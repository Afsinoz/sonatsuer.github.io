<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>The blog of Sonat Süer</title>
 <link href="http://localhost:4000/atom.xml" rel="self"/>
 <link href="http://localhost:4000"/>
 <updated>2018-08-09T00:03:45+03:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Sonat Süer</name>
   <email></email>
 </author>

 
 <entry>
   <title>Monoid Homomorphisms (Part 2 of 2)</title>
   <link href="http://localhost:4000/higher-algebra/2018/08/09/monoid-homomorphisms-2.html"/>
   <updated>2018-08-09T00:00:00+03:00</updated>
   <id>http://localhost:4000/higher-algebra/2018/08/09/monoid-homomorphisms-2</id>
   <content type="html">&lt;h1 id=&quot;applicatives-as-monoid-homomorphisms&quot;&gt;Applicatives As Monoid Homomorphisms&lt;/h1&gt;
&lt;p&gt;In the last post I mentioned that a monoidal structure is actually a categorification of the notion of a monoid. In accordance with the main theme of these posts, we should ask the following question: What is a homomorphism between monoidal structures?&lt;/p&gt;

&lt;p&gt;Let us take two monoidal categories \(\mathcal{C}\) and \(\mathcal{D}\). The naive definition of a homomorphism of monoidal structures from \(\mathcal{C}\) to \(\mathcal{D}\) is a functor \(F:\mathcal{C}\to\mathcal{D}\) satisfying \(F(1)=1\) and \(F(a\otimes b) = F(a)\otimes F(b)\). The problem here is that two things are &lt;em&gt;very rarely&lt;/em&gt; equal. In a categorical concept, the relevant concept is isomorphism. However, even isomorphism can be a too strong requirement. Existence of a morphism is often enough to obtain a useful concept. Here is the weakened version of a monoidal homomorphism, also know as a lax monoidal functor: a functor \(F:\mathcal{C}\to\mathcal{D}\) is called a lax monoidal functor if there are a morphism \(\epsilon : 1 \to F(1)\) and a natural transformation \(\mu_{x,y}: F(a)\otimes F(b) \to F(a\otimes b)\), of course, with respect to some coherence conditions. You may have a look at &lt;a href=&quot;https://ncatlab.org/nlab/show/monoidal+functor&quot;&gt;nLab&lt;/a&gt; for the full definition. One can also define co-lax monoidal functors by reversing the arrows.&lt;/p&gt;

&lt;p&gt;I will give one obscure and one famous example from Haskell. The obscure example is the &lt;em&gt;Decisive&lt;/em&gt; typeclass that I have seen only once. Decisive functors are co-lax monoidal (endo)functors with respect to the sum. The other is, as you can guess from the title of this subsection, the Applicative typecalss. I will not go into the details as it is well documented, say, in &lt;a href=&quot;https://wiki.haskell.org/Typeclassopedia#Alternative_formulation&quot;&gt;Typeclassopedia&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So what? The api given by directly translating the definition is awkward as opposed the standard api which lets you do things like&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;curriedFunctionWithManyInputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;What did we gain here? The point is that your relationship with code is not limited to &lt;em&gt;typing&lt;/em&gt; it. Occasionally, you find yourself reasoning about code or even imagining code, possibly in an imaginary language! To know that applicative functors are actually homomorphisms offers the kind of wisdom you need when you are not necessarily in front of a keyboard. For instance, we have monad transformers but we do not have applicative transformers because the composition of applicative functors is already applicative, drum roll here, because composition of structure preserving maps is again structure preserving.&lt;/p&gt;

&lt;h1 id=&quot;homomorphisms-of-applicatives&quot;&gt;Homomorphisms of Applicatives&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Day convolution is just the categorification of the notion of a convolution on a free \(R\)-algebra on a monoid where \(R\) is a commutative unital ring, what’s the problem?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Well, at this point, I could vomit my &lt;em&gt;déformation professionnelle&lt;/em&gt; in your general direction to explain what that means… But I won’t, at least not in this post. I will only say that there is a general way of viewing lax monoidal functors as monoid objects in a monoidal category where Day convolution gives the underlying monoidal structure. I will also practice something I do not usually preach: I will work with an implementation of Day convolution in Haskell instead of working with the specification.&lt;/p&gt;

&lt;p&gt;I will borrow the definitions/implementations from &lt;a href=&quot;https://hackage.haskell.org/package/contravariant-0.6.1/docs/Data-Functor-Day.html&quot;&gt;Data.Functor.Day&lt;/a&gt; with minor modifications.&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kr&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forall&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;kr&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;forall&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- The identity is the identity functor&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;-- This corresponds to the 'multiplication' of the monoidal structure.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Applicative&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dap&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;-- These functions are used to map over components.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trans1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trans1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fg&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hc&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fg&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hc&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;trans2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trans2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gh&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gh&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;transBoth&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transBoth&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph22&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trans1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trans2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now suppose &lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;g&lt;/code&gt; are two applicative functors (viewed as monoid objects) and&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is a homomorpism from &lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;g&lt;/code&gt;. Then we must have&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;dap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transBoth&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Day&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Simplifying yields&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Since this holds for any &lt;code class=&quot;highlighter-rouge&quot;&gt;op&lt;/code&gt;, it also holds for &lt;code class=&quot;highlighter-rouge&quot;&gt;(,)&lt;/code&gt;. So we get the even simpler form&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note that we can actually recover the previous equation by mapping &lt;code class=&quot;highlighter-rouge&quot;&gt;uncurry op&lt;/code&gt; to both sides. So we can use the last equation together with&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pure&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;to define applicative-viewed-as-a-monoid homomorphisms. This is a little bit disappointing because we just reinvented the notion of a monoidal natural transformation. On the other hand we learned that monoidal natural transformations can be seen as monoid object morphisms. This is a neat fact and it allows us, for instance, to transfer homomorphism related concepts to applicative functors. Cayley representation is one of them. Have a look at &lt;em&gt;Notions of Computation as Monoids&lt;/em&gt; by Rivas and Jaskelioff for details.&lt;/p&gt;

&lt;p&gt;Let us look at a few concrete examples. Let &lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt; be &lt;code class=&quot;highlighter-rouge&quot;&gt;Maybe&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;g&lt;/code&gt; be &lt;code class=&quot;highlighter-rouge&quot;&gt;[]&lt;/code&gt;. Consider &lt;code class=&quot;highlighter-rouge&quot;&gt;maybeToList&lt;/code&gt; from the first part. I claim that &lt;code class=&quot;highlighter-rouge&quot;&gt;maybetoList&lt;/code&gt; is an applicative homomorphism. Clearly&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;maybeToList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maybeToList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Just&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;We also need to verify the following equality:&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maybeToList&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maybeToList&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maybeToList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;fa :: Maybe a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;fb :: Maybe b&lt;/code&gt;. If at least one of &lt;code class=&quot;highlighter-rouge&quot;&gt;fa&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;fb&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;Nothing&lt;/code&gt; then both sides are &lt;code class=&quot;highlighter-rouge&quot;&gt;[]&lt;/code&gt;. If &lt;code class=&quot;highlighter-rouge&quot;&gt;fa = Just x&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;fb = Just y&lt;/code&gt; then both sides are equal to &lt;code class=&quot;highlighter-rouge&quot;&gt;[(x, y)]&lt;/code&gt;. This finishes our little proof.&lt;/p&gt;

&lt;p&gt;Actually something more general is going on here. Recall that &lt;code class=&quot;highlighter-rouge&quot;&gt;maybetoList&lt;/code&gt; is also a monad homomorphism and our applicatives are induced by monad instances. So it is very natural to conjecture that all monad homomorphisms are also applicative homomorphisms with respect to the induced applicative structures. So let us prove this conjecture.&lt;/p&gt;

&lt;p&gt;Let &lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt; be monads and let &lt;code class=&quot;highlighter-rouge&quot;&gt;morh :: m ~&amp;gt; n&lt;/code&gt; be a monad homomorphism. Then &lt;code class=&quot;highlighter-rouge&quot;&gt;morph . pure = pure&lt;/code&gt; as &lt;code class=&quot;highlighter-rouge&quot;&gt;return = pure&lt;/code&gt;. The other equality we need to prove turns into the following one&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftM2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftM2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;as &lt;code class=&quot;highlighter-rouge&quot;&gt;liftA2 = liftM2&lt;/code&gt;. We know that&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;liftM2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mx&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Since &lt;code class=&quot;highlighter-rouge&quot;&gt;morph&lt;/code&gt; is a monad homomorphism we have&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now combining these two we get&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftM2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;\&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftM2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which proves that &lt;code class=&quot;highlighter-rouge&quot;&gt;morph&lt;/code&gt; is also an applicative homomorphism.&lt;/p&gt;

&lt;p&gt;We may also conjecture that any applicative homomorphism between monads is also a monad homomorphism but it is not true! Recall from the first part that &lt;code class=&quot;highlighter-rouge&quot;&gt;listToMaybe&lt;/code&gt; is not a monad homomorphism. We will now show that it is actually an applicative homomorphism. The only nontrivial equation to check is the following:&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;fa :: [a]&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;fb :: [b]&lt;/code&gt;. If at least one of &lt;code class=&quot;highlighter-rouge&quot;&gt;fa&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;fb&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;[]&lt;/code&gt; then both sides are &lt;code class=&quot;highlighter-rouge&quot;&gt;Nothing&lt;/code&gt;. If &lt;code class=&quot;highlighter-rouge&quot;&gt;fa = x : xs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;fb = y : ys&lt;/code&gt; then both sides are equal to &lt;code class=&quot;highlighter-rouge&quot;&gt;Just (x, y)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Of course there are other examples of applicative homomorphisms, for instance &lt;code class=&quot;highlighter-rouge&quot;&gt;retractAp&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;hoistAp t&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;runAp t&lt;/code&gt; from &lt;a href=&quot;http://hackage.haskell.org/package/free-5.1/docs/Control-Applicative-Free.html&quot;&gt;Control.Applicative.Free&lt;/a&gt;, though they are called monoidal natural transformations in the documentation.&lt;/p&gt;

&lt;h1 id=&quot;one-more-examples-of-an-applicative-homomorphism&quot;&gt;One More Examples of an Applicative Homomorphism&lt;/h1&gt;

&lt;p&gt;Note that in &lt;code class=&quot;highlighter-rouge&quot;&gt;hoistAp t&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;runAp t&lt;/code&gt; there is no restriction on &lt;code class=&quot;highlighter-rouge&quot;&gt;t&lt;/code&gt; other than being a natural transformation. This may look odd, but really it is not because &lt;code class=&quot;highlighter-rouge&quot;&gt;Ap&lt;/code&gt; is the free part of a free-forgetful adjunction and if you are on the &lt;em&gt;forgotten&lt;/em&gt; side of it, any natural transformation is a morphism as there is no structure to preserve. In general, though, such effortless theorems are rare. If you want to prove something you need to assume something. I want to give an example which depends on an algebraic assumption.&lt;/p&gt;

&lt;p&gt;I will use the &lt;code class=&quot;highlighter-rouge&quot;&gt;Validation&lt;/code&gt; typeclass from &lt;a href=&quot;http://hackage.haskell.org/package/validation-1/docs/Data-Validation.html&quot;&gt;Data.Validation&lt;/a&gt;. Let me copy the relevant parts of the library here.&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kr&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Validation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;

&lt;span class=&quot;kr&quot;&gt;instance&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Semigroup&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Applicative&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Validation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;where&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As you can see, this is very much like &lt;code class=&quot;highlighter-rouge&quot;&gt;Either&lt;/code&gt; but the errors are accumulated using the semigroup structure as opposed to &lt;code class=&quot;highlighter-rouge&quot;&gt;Either&lt;/code&gt; which only keeps the first error. One nice thing about the &lt;code class=&quot;highlighter-rouge&quot;&gt;Validation&lt;/code&gt; is that its applicative instance is almost never induced by a monad instance.&lt;/p&gt;

&lt;p&gt;Now suppose that you want to change the error type you want from, say, &lt;code class=&quot;highlighter-rouge&quot;&gt;err1&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;err2&lt;/code&gt; using a function &lt;code class=&quot;highlighter-rouge&quot;&gt;convert :: err1 -&amp;gt; err2&lt;/code&gt;. We can implement this easily by&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;err1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Validation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err1&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Validation&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Now comes the interesting question: When is &lt;code class=&quot;highlighter-rouge&quot;&gt;changeErr&lt;/code&gt; an applicative homomorphism? Obviously&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So we need to check&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fa&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fb&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;fa :: Validation err1 a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;fb :: Validation err2 b&lt;/code&gt;. The proof is going to be a little boring because I will look at all four possible cases.&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Success&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;These equations hold without any assumption on &lt;code class=&quot;highlighter-rouge&quot;&gt;convert&lt;/code&gt;. However, the final case reveals something:&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;liftA2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(,)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Failure&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This shows that &lt;code class=&quot;highlighter-rouge&quot;&gt;changeErr convert&lt;/code&gt; is an applicative homomorphism if and only if &lt;code class=&quot;highlighter-rouge&quot;&gt;convert&lt;/code&gt; is a semigroup homomorphism. So, if &lt;code class=&quot;highlighter-rouge&quot;&gt;convert&lt;/code&gt; is a semigroup homomorphism, then ew have&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vn&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v1&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v2&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v3&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v4&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;lt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;changeErr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;convert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vn&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;f&lt;/code&gt; is a curried function with n many inputs. Therefore we can choose the more efficient one by comparing the costs of converting an error from &lt;code class=&quot;highlighter-rouge&quot;&gt;err1&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;err2&lt;/code&gt;, accumulating errors in &lt;code class=&quot;highlighter-rouge&quot;&gt;err1&lt;/code&gt; and accumulating errors in &lt;code class=&quot;highlighter-rouge&quot;&gt;err2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;By the way, one can also find algebraic assumptions like this in the wild, too. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Action&lt;/code&gt; instance of &lt;code class=&quot;highlighter-rouge&quot;&gt;Endo a&lt;/code&gt; on &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; from &lt;a href=&quot;http://hackage.haskell.org/package/monoid-extras-0.5/docs/Data-Monoid-Action.html&quot;&gt;Data.Monoid.Action&lt;/a&gt; is an example.&lt;/p&gt;

&lt;h1 id=&quot;the-take-home-message&quot;&gt;The Take-Home Message&lt;/h1&gt;

&lt;p&gt;The take-home message should be compact (and I am tired) so I will be brief: If you are going to work with objects with structure, do not neglect the structure preserving maps between them!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Monoid Homomorphisms (Part 1 of 2)</title>
   <link href="http://localhost:4000/higher-algebra/2018/07/30/monoid-homomorphisms-1.html"/>
   <updated>2018-07-30T00:00:00+03:00</updated>
   <id>http://localhost:4000/higher-algebra/2018/07/30/monoid-homomorphisms-1</id>
   <content type="html">&lt;h1 id=&quot;abstract-algebra-and-programming&quot;&gt;Abstract Algebra and Programming&lt;/h1&gt;

&lt;p&gt;Haskell community in particular and the functional programming community in general adopted a lot of useful algebraic structures, such as semigroups,monoids, (linear) orders, monads, categories etc. However, in the vast majority of the cases, this adoption has been at the level of of individual objects as opposed to adopting the category they form. People talk about monoids, however you do not hear many programmers talking about the &lt;em&gt;category&lt;/em&gt; of monoids, for instance. Similarly, you do not see many type class instances which use an assumption that a certain map is actually a morphism in some category. One notable exception is Kmett’s monad homomorphism library, which treats monads as a category.&lt;/p&gt;

&lt;p&gt;From an ex-mathematicians point of view, most functional programmers learning category theory seem to have blind spot there. There is this whole genre of categories where objects are &lt;em&gt;sets with extra structure&lt;/em&gt; and morphisms are &lt;em&gt;structure preserving functions&lt;/em&gt;. For the working programmer, a category usually consists of types and functions you can define between them. The extra structure part is completely lost. A function is merely a way to get from type a to type b. It is not seen as a means to carry or translate structure.&lt;/p&gt;

&lt;p&gt;This is not a big loss, of course, because most of the time the category at at hand &lt;em&gt;does&lt;/em&gt; consist of types in a programming language and functions you can define between them. However, I think, the &lt;em&gt;morphisms preserve structure&lt;/em&gt; approach has its use cases.&lt;/p&gt;

&lt;h1 id=&quot;monoids&quot;&gt;Monoids&lt;/h1&gt;
&lt;p&gt;Let’s look at a concrete example. A monoid is a triple \((M, \star, 1_M)\) where \(M\) is a set, \(\star\) is a binary operation on \(M\) and \(1_M\) is an element of \(M\) subject to the following conditions, called the monoid axioms:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\star\) is associative, i.e. \(x\star(y\star z) = (x\star y) \star z\) for all \(x,y,z\in M\),&lt;/li&gt;
  &lt;li&gt;\(1_M\) is the identity of the operation \(\star\), i.e. \(1_M\star x = x = x\star 1_M\) for all \(x\in M\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So monoids are sets with extra structure. Now let us define what it means for a function to preserve this structure. A monoid homomorphism from a monoid \((M,\star, 1_M)\) to \((N, \ast, 1_N)\) is a function \(\varphi : M\to N\) which satisfies&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\varphi(1_M) = 1_N\) and&lt;/li&gt;
  &lt;li&gt;\(\varphi(x \star y) = \varphi(x) \ast \varphi (y)\).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the definition of monoid homomorphism does not depend on the monoid axioms but only on the operations needed to define a monoid.&lt;/p&gt;

&lt;p&gt;Here are two monoids: \((\mathbb{R}, +, 0)\) and \((\mathbb{R}^{&amp;gt;0}, \cdot, 1)\). And here are two famous monoid homomorphisms: \(\log:\mathbb{R}^{&amp;gt;0}\to\mathbb{R}\) and \(\exp:\mathbb{R}\to\mathbb{R}^{&amp;gt;0}\), which happen to be inverse to each other.&lt;/p&gt;

&lt;p&gt;Now comes the interesting part. Suppose we need to multiply two large numbers, say \(x\) and \(y\). The obvious thing is to use a computer or a calculator. But there is also an outdated alternative: logarithm tables. We simply look up the logarithms of \(x\) and \(y\), add the results, and using the logarithm table (and the fact that \(\log\) is monotone increasing) compute the exponential. More symbolically, we use the following identity:
\[
  x\cdot y = \exp ( \log(x) + \log(y)).
\]
Let us go over what we did here. We took a &lt;em&gt;computation&lt;/em&gt; in \(\mathbb{R}^{&amp;gt;0}\), namely \(x\cdot y\), and pushed it to \(\mathbb{R}\) using \(\log\). This made the computation easier as addition is easier than multiplication. Then we pushed the result back in \(\mathbb{R}^{&amp;gt;0}\) where we needed it. This idea is very common in mathematics. For instance, Hughes’ difference lists also use monoid homomorphisms. In that case the role of \(\log\) is played by the Cayley representation map. I actually wrote about it &lt;a href=&quot;https://sonatsuer.github.io/evangelism/2018/07/23/invitation.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;categorification&quot;&gt;Categorification&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;A monad is just a monoid in the category of endofunctors, what’s the problem?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The problem is that the monoidal structure on the endofunctor category is not specified. Joking aside, it has been almost 10 years since Dan Piponi wrote a blog post titled &lt;a href=&quot;http://blog.sigfpe.com/2008/11/from-monoids-to-monads.html&quot;&gt;From Monoids to Monads&lt;/a&gt;. So I will not explain how the notion of monad is a categorified version of the notion of a monoid. However, mostly to fix notation, I will explain what the notion of the category of monoid objects in an arbitrary monoidal category is.&lt;/p&gt;

&lt;p&gt;Let us start with usual monoids in the category of sets. The first step is to express everything using functions in the point-free style. The binary operation on a monoid is already a function. But how do we talk about the identity element? The idea is to view the identity as a &lt;em&gt;nullary&lt;/em&gt; operation, that is, a function from the zeroth cartesian power of the monoid to itself. The zeroth power of a set is a set with a single element, also known as a singleton. So a nullary operation on a set \(X\) is simply a function from a singleton to \(X\), which is obviously determined by the unique element in its image. This means that we can identify nullary operations on \(X\) with elements of \(X\).&lt;/p&gt;

&lt;p&gt;Now let us rephrase the definition of a monoid without referring to elements. Fix a singleton \(1\). A monoid is a triple \((M, \star, 1_M)\) where \(\star\) and \(1_M\) are binary and nullary operations, respectively, on \(M\) where the following diagrams commute:&lt;/p&gt;

&lt;p&gt;\(
\newcommand{\ra}[1]{\kern-1.5ex\xrightarrow{\ \ #1\ \ }\phantom{}\kern-1.5ex}
\newcommand{\ras}[1]{\kern-1.5ex\xrightarrow{\ \ \smash{#1}\ \ }\phantom{}\kern-1.5ex}
\newcommand{\da}[1]{\bigg\downarrow\raise.5ex\rlap{\scriptstyle#1}}
\newcommand{\id}{\textrm{id}}
\)&lt;/p&gt;

&lt;p&gt;\[
\begin{array}{c}
1 \times M &amp;amp; \ras{1_M \times \id} &amp;amp; M \times M \newline
\da{\id} &amp;amp; &amp;amp; \da{\star} \newline
1 \times M &amp;amp; \ras{\;\;\lambda\;\;} &amp;amp; M, \newline
\end{array}
\;\;\;\;\;\;\;\;\;
\begin{array}{c}
M \times 1 &amp;amp; \ras{1_M \times \id} &amp;amp; M \times M \newline
\da{\id} &amp;amp; &amp;amp; \da{\star} \newline
M \times 1 &amp;amp; \ras{\;\;\rho\;\;} &amp;amp; M \newline
\end{array}
\]
and
\[
\begin{array}{c}
(M \times M) \times M &amp;amp; \ras{\alpha}\;\;\;\; M \times (M\times M)\;\;\;\; \ras{\star} &amp;amp; M \times M \newline
\da{\star} &amp;amp; &amp;amp; \da{\star} \newline
M \times M &amp;amp; \ras{\;\;\;\;\;\;\;\;\;\;\;\;\;\;\star\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;\;} &amp;amp; M. \newline
\end{array}
\]&lt;/p&gt;

&lt;p&gt;Here \(\lambda\) and \(\rho\) are projections and \(\alpha((x,y), z) = (x,(y,z))\). A function \(\varphi:M\to N\) is a monoid homomorphism from \((M,\star,1_M)\) to \((N,\ast, 1_N)\) if the following diagrams commute:&lt;/p&gt;

&lt;p&gt;\[
\begin{array}{c}
1 &amp;amp; \ras{1_M} &amp;amp; M \newline
\da{\id} &amp;amp; &amp;amp; \da{\varphi} \newline
1 &amp;amp; \ras{1_N} &amp;amp; N, \newline
\end{array}
\;\;\;\;\;\;\;\;\;
\begin{array}{c}
M \times M &amp;amp; \ras{\varphi \times \varphi} &amp;amp; N \times N \newline
\da{\star} &amp;amp; &amp;amp; \da{\ast} \newline
M &amp;amp; \ras{\varphi} &amp;amp; N. \newline
\end{array}
\]&lt;/p&gt;

&lt;p&gt;This formulation tells us that in any category with finite products we can talk about monoids and monoid homomorphisms. For instance if we replace the category of sets by topological spaces (with continuous maps) we obtain the notion of a topological monoid. We will do something better, though. We will isolate the properties of category theoretic product we needed in the definitions above. This will give us a notion of an abstract product which will yield the notion a  monoidal category.&lt;/p&gt;

&lt;p&gt;Let \(C\) be an arbitrary category. Let \(\otimes\) be our abstract product on \(C\).We want to be able replace every occurrence of \(\times\) above by \(\otimes\). First of all we should have
\[
\otimes : C \times C \to C
\]
because a product takes two objects and produces one. We also need \(f\otimes g\) where \(f\times g\) is a functor from \(C\times C\) to itself. So let us take \(\otimes\) to be a functor. What else? We need analogues of \(1\), \(\lambda\), \(\rho\) and \(\alpha\).&lt;/p&gt;

&lt;p&gt;In the case of cartesian product, \(1\) is the zeroth power of any object. This is essentially saying that our tensor should have a two sided identity, &lt;em&gt;up to isomorphism&lt;/em&gt;. Now looking at the diagrams above, we see that, \(\lambda\) and \(\rho\) exactly do that. Finally, we need a family of isomorphism
\[
  \alpha_{a,b,c} : (a\otimes b)\otimes c\to a\otimes(b\otimes c)
\]
natural in \(a\), \(b\) and \(c\).&lt;/p&gt;

&lt;p&gt;It may seem that this is enough, however we also need some coherence conditions. Here is the problem. Obviously
\[
  ( a \times (b \times (c \times d))
  \;\;\text{ and }\;\;
  (((a \times b) \times c) \times d
\]
are isomorphic, naturally in \(a\), \(b\), \(c\) and \(d\), but if we want to construct an actual isomorphism using \(\alpha\) we have, a priori, two choices:
\[
\alpha_{a\times b, c, d} \circ \alpha_{a,b,c\times d}
\]
and
\[
(\id_a \times \alpha_{b,c,d}) \circ \alpha_{a, b\times c, d} \circ (\alpha_{a,b,c}\times \id_z)
\]
It happens that these are the same isomorphism but there is nothing guaranteeing that the same will hold for an arbitrary \(\otimes\). We want our isomorphisms to be unique provided that they are constructed from \(\alpha\), \(\lambda\) and \(\rho\). It turns out that this can be achieved by assuming two simple laws, the so called pentagon law –this is actually what we just wrote– and the so called triangle law –a coherence condition regarding the identity. For details, you may have a look at &lt;a href=&quot;https://ncatlab.org/nlab/show/monoidal+category&quot;&gt;nLab&lt;/a&gt;. So a monoidal category is a category with a product satisfying the pentagon and the triangle laws.&lt;/p&gt;

&lt;p&gt;Now if you stop for a second and squint at the screen, you may realize that a monoidal structure is a monoid where operations are defined &lt;em&gt;up to isomorphism&lt;/em&gt;. So the notion of a monoidal category is also a categorification of the notion of a monoid, though in a entirely different direction. But then what is the correct notion of homomorphism here? We’ll see that when we come to applicative functors.&lt;/p&gt;

&lt;h1 id=&quot;monad-homomorphisms&quot;&gt;Monad Homomorphisms&lt;/h1&gt;
&lt;p&gt;\(\newcommand{\end}[1]{\textrm{End}(#1)}\)
Given a category \(C\), let \(\end{C}\) be the category of functors from \(C\) to itself where the morphisms are given by natural transformations. Functor composition gives a natural monoidal structure on \(\end{C}\) and the monoidal objects in this category are called, you guessed it, monads.&lt;/p&gt;

&lt;p&gt;Now let’s look at monad homomorphisms. Here, I will switch to Haskell notation. Whether I can or should switch to Haskell like that is the subject of an entirely different &lt;a href=&quot;http://math.andrej.com/2016/08/06/hask-is-not-a-category/&quot;&gt;discussion&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let us specialize the definition of a homomorphism to our case. Let &lt;code class=&quot;highlighter-rouge&quot;&gt;m&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;n&lt;/code&gt; be monads. A monad homomorphism is a natural transformation &lt;code class=&quot;highlighter-rouge&quot;&gt;morph :: forall a. m a -&amp;gt; n a&lt;/code&gt; satisfying the following properties:&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fmap&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The second law is equivalent o&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;if you are used to thinking in terms of &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&amp;gt;=&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For a list of examples you may have a look at &lt;a href=&quot;https://gist.github.com/ekmett/48f1b578cadeeaeee7a309ec6933d7ec&quot;&gt;this&lt;/a&gt; gist which has cute homomorphisms like &lt;code class=&quot;highlighter-rouge&quot;&gt;readOnly&lt;/code&gt; which is not in &lt;a href=&quot;http://hackage.haskell.org/package/mmorph-1.1.2/docs/Control-Monad-Morph.html&quot;&gt;Control.Monad.Morph&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So what is the merit of knowing that, say &lt;code class=&quot;highlighter-rouge&quot;&gt;lift&lt;/code&gt;, is a monad homomorphism? Well, when you think about it, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;lift&lt;/code&gt; when we are in the wrong monad. That is, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;lift&lt;/code&gt; to get from type a to type b just as I mentioned in the beginning. Indeed, if you have only one monadic value, this is all you can do with &lt;code class=&quot;highlighter-rouge&quot;&gt;lift&lt;/code&gt;. The fact that &lt;code class=&quot;highlighter-rouge&quot;&gt;lift&lt;/code&gt; is a homomorphism becomes useful when we want to lift many values. For instance we have&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;forM_&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lift&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lift&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forM_&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;mapM_&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lift&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lift&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mapM_&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;And since lifting has a cost, the forms on the right hand side are usually more efficient.&lt;/p&gt;

&lt;p&gt;I would like to finish this part by giving an example of a natural transformation which is not a monad homomorphism. Let &lt;code class=&quot;highlighter-rouge&quot;&gt;listToMaybe&lt;/code&gt; be defined by &lt;code class=&quot;highlighter-rouge&quot;&gt;foldr (const . Just) Nothing&lt;/code&gt;. Then &lt;code class=&quot;highlighter-rouge&quot;&gt;listToMaybe&lt;/code&gt; is not a monad homomorphism. Indeed,&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Just&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;but&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;$&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;listToMaybe&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Just&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;join&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;Just&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Nothing&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;Nothing&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;On the other hand, &lt;code class=&quot;highlighter-rouge&quot;&gt;maybeToList&lt;/code&gt; defined by &lt;code class=&quot;highlighter-rouge&quot;&gt;foldr (:) []&lt;/code&gt; &lt;em&gt;is&lt;/em&gt; a monad homomorphism.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>An Invitation to Functional Programming (For Mathematicians)</title>
   <link href="http://localhost:4000/evangelism/2018/07/23/invitation.html"/>
   <updated>2018-07-23T00:00:00+03:00</updated>
   <id>http://localhost:4000/evangelism/2018/07/23/invitation</id>
   <content type="html">&lt;p&gt;(This post is based on two talks I gave at the mathematics departments of Bilkent University and METU.)&lt;/p&gt;

&lt;h1 id=&quot;functional-programming&quot;&gt;Functional Programming&lt;/h1&gt;

&lt;p&gt;Here is the definition of functional programing in Wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;In computer science, functional programming is a programming paradigm that treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This should be very appealing to mathematicians. The reason is that choosing pure –i.e. mathematical– functions as a foundation means that programs are &lt;em&gt;algebraic&lt;/em&gt; objects. Computation is literally simplification of algebraic expressions.&lt;/p&gt;

&lt;p&gt;This paradigm is very intuitive from the point of view of a mathematician. For instance, we can use &lt;em&gt;substitution of equals for equals principle&lt;/em&gt;, a principle we learn in primary school, as a way to reason bout programs. This is also very useful from the point of view of a programmer. It even has a fancy name in computer science. It is called &lt;em&gt;referential transparency&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;However, somewhat surprisingly, functional programming is considered difficult by a lot of programmers. Personally, I think programmers find it difficult because to be productive in a purely functional language, first they need to &lt;em&gt;unlearn&lt;/em&gt; an entire paradigm which they have been using for years. This is where the mathematicians have the advantage. A mathematician only needs to &lt;em&gt;learn&lt;/em&gt; the specifics of a programming language based on ideas with which he/she is already familiar. Learning is generally easier than unlearning.&lt;/p&gt;

&lt;p&gt;In this post, I will try to lure you, my dear mathematician, into functional programming.&lt;/p&gt;

&lt;h1 id=&quot;enter-haskell&quot;&gt;Enter Haskell&lt;/h1&gt;

&lt;p&gt;We will work out an example of the &lt;em&gt;programs are algebraic objects&lt;/em&gt; approach in detail. For that we will use Haskell, an industrial strength pure functional language, named after the mathematician and logician Haskell Curry. This will not be a crash course in Haskell. Instead, I will explain the syntax as we go.&lt;/p&gt;

&lt;p&gt;Like the vast majority of programming languages, Haskell has data structures. One of the most common data structures in Haskell is the  list structure. Here is the definition: given a type &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;, (like integers, floating point numbers, strings, etc.) we define &lt;code class=&quot;highlighter-rouge&quot;&gt;[a]&lt;/code&gt; by &lt;em&gt;structural recursion&lt;/em&gt; as follows:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;[]&lt;/code&gt; is a list, it is called the empty list;&lt;/li&gt;
  &lt;li&gt;if &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; is an element of type &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; is a list of elements of type &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; then &lt;code class=&quot;highlighter-rouge&quot;&gt;x : xs&lt;/code&gt; is also list.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For instance&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1 : (2 : (3 : [])) = 1 : 2 : 3 : []
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;is a list of integers. Haskell allows us to express this list as &lt;code class=&quot;highlighter-rouge&quot;&gt;[1, 2, 3]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Note that here &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; is a actually &lt;em&gt;binary operation&lt;/em&gt; and a list actually a &lt;em&gt;term&lt;/em&gt;. Now let us define a simple function on lists.&lt;/p&gt;

&lt;p&gt;Let &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ys&lt;/code&gt; be two lists (over the same type). We define the concatenation &lt;code class=&quot;highlighter-rouge&quot;&gt;xs++ys&lt;/code&gt; of &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ys&lt;/code&gt; by recursion on the structure of &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[]++ys = ys    and    (x : xs') ++ ys = x : (xs' ++ ys).
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let us compute an example:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[1,2]++[3,4] = (1 : (2 : [] )) ++ (3 : (4 : []))
             = 1 : (( 2 : []) ++ (3 : (4 : []))
             = 1 : (2 : ([] ++ (3 : (4 : [])))
             = 1 : (2 : (3 : (4 : [])))
             = [1,2,3,4]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note the similarity between this calculation and the calculations you do in algebra.&lt;/p&gt;

&lt;h1 id=&quot;our-first-program-in-haskell&quot;&gt;Our First Program in Haskell&lt;/h1&gt;

&lt;p&gt;Suppose that we want to devise a function –that is to say, write a program– which produces the reverse of a list. Here is the obvious solution. Given a list &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; let us define &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse&lt;/code&gt; as follows:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;naiveReverse [] = []
naiveReverse (x : xs) = naiveReverse xs ++ [x]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;This looks like a (recursive) mathematical definition but it is actually valid Haskell code. As an exercise you may want to show that &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse [1,2,3] = [3,2,1]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Our program solves the problem of inverting a list, however we call it the naive reverse for a reason. It is not very efficient. First, note that the computation of &lt;code class=&quot;highlighter-rouge&quot;&gt;xs ++ ys&lt;/code&gt; requires length of &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; many applications of &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; operation. This causes the computation to &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse xs&lt;/code&gt; to require \(\frac{1}{2}n(n-1)\) applications of the operation &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; where \(n\) is the length of &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We can easily prove this by induction on \(n\). Base case is trivial. Suppose the statement holds for \(n\). Let &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; be of length \(n\). Then, for any &lt;code class=&quot;highlighter-rouge&quot;&gt;x&lt;/code&gt; we have
\[
{\rm naiveReverse}\, (x : xs) = {\rm naiveReverse}\, xs ++ [x].
\]
As &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse xs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;xs&lt;/code&gt; has the same length, namely \(n\), computation of &lt;code class=&quot;highlighter-rouge&quot;&gt;++&lt;/code&gt; takes \(n\) applications of the &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; operation. On the other hand, by induction hypothesis, &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse xs&lt;/code&gt; requires \(\frac{1}{2}n(n-1)\) applications. Adding these two yields \(\frac{1}{2}n(n+1)\), which is what we want.&lt;/p&gt;

&lt;p&gt;So the complexity of &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse&lt;/code&gt; is quadratic as a function of the input length because &lt;code class=&quot;highlighter-rouge&quot;&gt;++&lt;/code&gt; is expensive. There is a very similar situation in mathematics with an elegant solution: multiplication is expensive, however one can use logarithms to turn multiplication into addition, do the addition and come back with exponentiation. This is why logarithm tables were used before computers.&lt;/p&gt;

&lt;p&gt;We will use the same trick to optimize &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse&lt;/code&gt;, that is, we will change the underlying monoid using a homomorphism.&lt;/p&gt;

&lt;h1 id=&quot;algebra-refresher&quot;&gt;Algebra Refresher&lt;/h1&gt;
&lt;p&gt;Recall that a monoid is a triple \((M, \cdot, 1_M)\) where \(\cdot\) is a binary associative operation on \(M\) and \(1_M\) is the identity element of \(\cdot\).&lt;/p&gt;

&lt;p&gt;Here are a few examples. For any set \(S\), the set of self maps of \(S\), denoted by \({\rm End}(S)\) is a monoid under composition. The identity is the identity function. For any set \(S\), the set of finite sequences with elements from \(S\) form a monoid under concatenation. The identity is the empty list. This is called the free monoid generated by \(S\).&lt;/p&gt;

&lt;p&gt;A monoid homomorphism from \((M, \cdot, 1_M)\) to \((N, \star, 1_N)\) is a function \(\varphi : M \to N\) such that \(\varphi(1_M) = 1_N\) and
\(\varphi(x\cdot y) = \varphi(x)\star\varphi(y)\).&lt;/p&gt;

&lt;p&gt;The Cayley representation theorem, which is taught in every every abstract algebra course, says that the map \(\mathcal{C} : M\to {\rm End}(M)\) defined by \(\varphi(m)(n) = m \cdot n \) is an injective monoid homomorphism, i.e. a monoid embedding. Note that if a function \(f\) is in the image of \(\mathcal{C}\) then one can recover the element it came from by applying \(f\) to the identity of the monoid.&lt;/p&gt;

&lt;p&gt;Using the Cayley representation theorem, we can push the problem of computing inverses to the monoid \({\rm End}([a])\). (Note how I mixed the Haskell notation and standard mathematical notation.) The advantage is that in \({\rm End}([a])\), the monoidal operation, namely function composition, is very cheap. To be more precise, it requires constant time because the composition of two functions is left untouched until someone tries to apply it to a value. However, the notion of reverting only makes sense in \([a]\) and not in \({\rm End}([a])\). So we need to embed only the concatenation part of the problem into \({\rm End}([a])\).&lt;/p&gt;

&lt;p&gt;Here is the solution as valid Haskell code:&lt;/p&gt;
&lt;div class=&quot;language-haskell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kr&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;End&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;naiveReverse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;naiveReverse&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;naiveReverse&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;naiveReverse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;singleton&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;End&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;singleton&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;cayleyReverse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;End&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cayleyReverse&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cayleyReverse&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cayleyReverse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;singleton&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;betterReverse&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;betterReverse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cayleyReverse&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xs&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;[]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that &lt;code class=&quot;highlighter-rouge&quot;&gt;cayleyReverse&lt;/code&gt; is obtained from &lt;code class=&quot;highlighter-rouge&quot;&gt;naiveReverse&lt;/code&gt; in a mechanical way replacing &lt;code class=&quot;highlighter-rouge&quot;&gt;++&lt;/code&gt; by &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;[x]&lt;/code&gt; by &lt;code class=&quot;highlighter-rouge&quot;&gt;singleton x&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;final-remarks&quot;&gt;Final Remarks&lt;/h1&gt;

&lt;p&gt;This idea can be vastly generalized, if you know some category theory. Instead of monoids you can work with monoid objects in certain monoidal categories and transfer this optimization technique to different contexts. If you are interested in the details, you may have a look at &lt;em&gt;Notions of Computation as Monoids&lt;/em&gt; by Exequiel Rivas and Mauro Jaskelioff.&lt;/p&gt;

&lt;p&gt;In the beginning, I said that I will try to lure you into functional programming. And the picture I tried to draw can be summarized by the famous motto:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;There is nothing more practical than a good theory.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;However, if you are really considering a career change like I did, there is another motto you should know about:&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;In theory, there is no difference between theory and practice. In practice, there is.&lt;/p&gt;
&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>Self Aware Programs</title>
   <link href="http://localhost:4000/recursion-theorem/2018/07/11/self-aware-programs.html"/>
   <updated>2018-07-11T00:00:00+03:00</updated>
   <id>http://localhost:4000/recursion-theorem/2018/07/11/self-aware-programs</id>
   <content type="html">&lt;h1 id=&quot;a-classical-exercise&quot;&gt;A Classical Exercise&lt;/h1&gt;

&lt;p&gt;A computer program which produces its own source code is called a quine, named after the logician Willard Van Orman Quine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Exercise:&lt;/strong&gt; Write a quine in your favorite programming language.&lt;/p&gt;

&lt;p&gt;If you haven’t solved this exercise before, I urge you to stop right now and give it a try.&lt;/p&gt;

&lt;p&gt;To give you an idea of why this is an interesting problem, let us try to solve it in a naive way. Instead of using an actual programming language
I will use pseudocode to keep things simple.&lt;/p&gt;

&lt;p&gt;The obvious candidate of a quine is&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Print your own source code
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This looks like cheating but actually there are languages which allow this. For instance&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;10 List
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;is a valid GWBasic program which, when run, prints &lt;code class=&quot;highlighter-rouge&quot;&gt;10 List&lt;/code&gt; on the screen. Actually, in GWBasic, &lt;em&gt;any&lt;/em&gt; code which starts with &lt;code class=&quot;highlighter-rouge&quot;&gt;10 List&lt;/code&gt;
is a quine.&lt;/p&gt;

&lt;p&gt;So, to make things less trivial and more generic, let us restrict ourselves to text manipulations. In this case, the first candidate is&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Print &quot;Print&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The output of this code is simply &lt;code class=&quot;highlighter-rouge&quot;&gt;Print&lt;/code&gt;. So it doesn’t work. Seeing this, you may try&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Print &quot;Print &quot;Print&quot;&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This time the output is &lt;code class=&quot;highlighter-rouge&quot;&gt;Print &quot;Print&quot;&lt;/code&gt;. Failed again. Actually, any code of the form &lt;code class=&quot;highlighter-rouge&quot;&gt;Print &quot;&amp;lt;any kind of fixed text&amp;gt;&quot;&lt;/code&gt; will fail
as the source code is strictly longer than the text it prints. Now here is an idea to circumvent this: We can use the the given text, or its parts, more than once!
So let us try a program like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be the following text:
&quot;&amp;lt;there is going to be a text here&amp;gt;&quot;
&amp;lt;there are going to be commands here explaining what to do with A&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As we will construct the source code using the parts of the text A, the first line of the code should be a part of A. So our program should look like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be the following text:
&quot;Let A be the following text:
&amp;lt;there are going to be more lines here&amp;gt;&quot;
&amp;lt;there are going to be commands here explaining what to do with A&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Of course, we will print the first line. Thus we should have a program like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be the following text:
&quot;Let A be the following text:
&amp;lt;there are going to be more lines here&amp;gt;&quot;
Print the first line of A
&amp;lt;there are going to be more commands here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Obviously the command &lt;code class=&quot;highlighter-rouge&quot;&gt;Print the first line of A&lt;/code&gt; should appear somewhere in A. So let’s add it to A to obtain&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be the following text:
&quot;Let A be the following text:
Print the first line of A
&amp;lt;there are going to be more lines here&amp;gt;&quot;
Print the first line of A
&amp;lt;there are going to be more commands here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now the second printing command should print what comes after the first line. But this is simply the text A in quotation. Therefore we should have&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be the following text:
&quot;Let A be the following text:
Print the first line of A
&amp;lt;there are going to be more lines here&amp;gt;&quot;
Print the first line of A
Print A in quotation
&amp;lt;there are going to be more commands here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Again these commands should appear in A. So we have&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be the following text:
&quot;Let A be the following text:
Print the first line of A
Print A in quotation
&amp;lt;there are going to be more lines here&amp;gt;&quot;
Print the first line of A
Print A in quotation
&amp;lt;there are going to be more commands here&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note that, up until now, all the steps we took were pretty much forced. The final step will be a little different and require a tid bit of creativity.
Here is our finished quine:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be the following text:
&quot;Let A be the following text:
Print the first line of A
Print A in quotation
Print A except for its first line&quot;
Print the first line of A
Print A in quotation
Print A except for its first line
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;As an exercise, you may translate this quine into a real programming language. Even though the quine above has the essential idea, you may still need to deal with a few language specific details such as escaping quotation marks. Here is one for you in Haskell meant to be evaluated in repl.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;let x = [&quot;let x = &quot;, &quot; in putStr (x !! 0) &amp;gt;&amp;gt; putStr (show x) &amp;gt;&amp;gt; putStr (x !! 1)&quot;] in putStr (x !! 0) &amp;gt;&amp;gt; putStr (show x) &amp;gt;&amp;gt; putStr (x !! 1)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now this was fun, bu also ad-hoc. The natural question to ask here whether there is a principled way of writing, not only quines, but programs which have some kind of access to their own source code. The answer is yes and this follows from one of the most fundamental results in recursion theory, the recursion theorem.&lt;/p&gt;

&lt;h1 id=&quot;kleenes-recursion-theorem&quot;&gt;Kleene’s Recursion Theorem&lt;/h1&gt;

&lt;p&gt;I want to work with a Turing complete programming language. Luckily, what we need is essentially what I described in the first section of
&lt;a href=&quot;https://sonatsuer.github.io/kolmogorov-complexity/2018/05/21/kolmogorov-complexity-1.html&quot;&gt;Kolmogorov Complexity (1/2)&lt;/a&gt;. The differences
are that we do not need \(\mathcal{L}\) to contain UTF-8 characters and we do not need an assumption on the way we represent natural numbers.&lt;/p&gt;

&lt;p&gt;Let \(\mathcal{M}\) be the set of all strings from \(\mathcal{L}\) and let \(\mathcal{C}(n)\) be the set of all source codes
expecting \(n\) inputs, where \(n\) is a natural number. Then, for each \(c\in\mathcal{C}(n)\), we have a partial function \(f_c\) from
\(\mathcal{M}^n\) to \(\mathcal{M}\), which is simply the partial function computed by the source code \(c\). These functions are called the computable partial functions.&lt;/p&gt;

&lt;p&gt;Let us start with a simple but useful lemma.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lemma:&lt;/strong&gt; There is a computable function \(s\) such that for any \(x\in\mathcal{M}\) and \(c\in\mathcal{C}(2)\) we have
\(s(c,x)\in\mathcal{C}(1)\) and
\[
   f_c(x,y) = f_{s(c,x)}(y).
\]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof:&lt;/strong&gt; Let \(x\in\mathcal{M}\) and \(c\in\mathcal{C}(2)\) be given. As \(c\in\mathcal{C}(2)\), \(c\) should look like this:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ask for a value from the user and store it as A
Ask for a value from the user and store it as B
&amp;lt;Some commands&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;All \(s\) will need to do is to convert this code into the following one:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Let A be x
Ask for a value from the user and store it as B
&amp;lt;Some commands&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In other words, it should hard-code the value \(x\). It is not difficult to imagine an algorithm doing this. Thus, by appealing to the Church-Turing hypothesis, we are done. \(\square\)&lt;/p&gt;

&lt;p&gt;Now we can prove the recursion theorem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem (Kleene):&lt;/strong&gt; Let \(f(x,y)\) be a partial two-variable computable function. Then there is a \(c\in\mathcal{C}(1)\) such that
\[
  f(c,y) = f_c(y)
\]
holds for all \(y\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof:&lt;/strong&gt; Let \(a\in\mathcal{C}(2)\) be such that \(f = f_a\). Such an \(a\) exists because this is what computable means. Now,
by the lemma, we already have something close, namely
\[
  f(x,y) = f_a(x,y) = f_{s(a,x)}(y).
\]
So, if we could find a solution for \(x = s(a,x)\), then we would be done. However, in this equation, we have some control over \(x\) but
the other parameter \(a\) is very heavily constrained since \(f = f_a\).&lt;/p&gt;

&lt;p&gt;Now comes the brilliant idea: instead of working with \(x\)
let us work with a computable function of \(x\). Consider \(f(g(x),y)\) for a not yet determined computable function. As both \(f\)
and \(g\) are computable, so is this new function. Therefore there is a \(b\in\mathcal{C}(2)\) such that \(f_b(x,y) = f(g(x),y)\). Now we have
\[
  f(g(x),y) = f_b(x,y) = f_{s(b,x)}(y)
\] so the equation we need to solve in this case is
\[
  g(x) = s(b, x)
\]
instead of \(x = s(a,x)\). Introducing \(g\) into the problem gave us some room because now we can choose both \(x\) &lt;em&gt;and&lt;/em&gt; \(g\). Squinting
at the equation for a few seconds, we see that there is a trivial solution, namely \(g(x) = s(x,x)\) and \(x = b\)! We were lucky! (Just kidding,
I planned all of this.)&lt;/p&gt;

&lt;p&gt;Let us summarize this “stream of consciousness” into a more traditional proof. Let \(b\in\mathcal{C}(2)\) be such that \(f_b(x,y) = f(s(x,x),y)\)
and let \(c = s(b,b)\). Then
\begin{align}
f(c,y) &amp;amp; = f (s (b,b), y) \newline
       &amp;amp; = f_b (b, y) \newline
       &amp;amp; = f_{s(b,b)}(y) \newline
       &amp;amp; = f_c(y)
\end{align}
This finishes the proof. \(\square\)&lt;/p&gt;

&lt;p&gt;Let us look at example to appreciate the power of this theorem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; There is a \(c\in\mathcal{C}(1)\) such \(f_c(y) = c\) for all \(y\). Note that \(c\) is just a quine.
Let \(f(x,y) = x\). Obviously \(f\) is computable. Thus, by the recursion theorem, there is a \(c\) such that
\[
  f_c(y) = f(c, y) = c
\]
for all \(y\).&lt;/p&gt;

&lt;p&gt;Here is another one.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; There is a \(c\in\mathcal{C}(1)\) such
\[
  f_c(y) =
  \begin{cases}
   \text{reversed } c, \text{ if $c$ is longer than $y$} \newline
   \text{collected works of Shakespeare}, \text{ otherwise}
  \end{cases}
\]
Let
\[
  f(x,y) =
  \begin{cases}
   \text{reversed } x, \text{ if $x$ is longer than $y$} \newline
   \text{collected works of Shakespeare}, \text{ otherwise}
  \end{cases}
\]
and apply the recursion theorem.&lt;/p&gt;

&lt;p&gt;The pattern here is clear: If you want to find a code in \(\mathcal{C}(1)\) which accesses its own source code, just write a code in
\(\mathcal{C}(2)\) which asks for its own source code as input from the user. The recursion theorem takes care of the rest. From now on, I will freely use a subroutine &lt;code class=&quot;highlighter-rouge&quot;&gt;access your own code&lt;/code&gt; and assume that you can implement it using the recursion theorem.&lt;/p&gt;

&lt;h1 id=&quot;unsolvable-problems&quot;&gt;Unsolvable Problems&lt;/h1&gt;

&lt;p&gt;Now we know how to fake an access-your-own-code subroutine. You might think that we can write amazing programs by using it but from a practical point of view such a subroutine is pretty useless. So what can we do with it? Well, mathematical logic of course! (See the last paragraph of &lt;a href=&quot;https://sonatsuer.github.io/kolmogorov-complexity/2018/05/21/kolmogorov-complexity-1.html&quot;&gt;Kolmogorov Complexity (1/2)&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;As a warmup exercise, let us prove the unsolvability of the halting problem using the recursion theorem. Of course there is a much simpler proof via diagonalization but, as I said, this is a warmup exercise. Suppose that the halting problem &lt;em&gt;is&lt;/em&gt; solvable. This means that the function defined by
\[
  f(c, x) =
  \begin{cases}
  \text{yes, }\, \text{if $c$ is in $\mathcal{C}(1)$ and $f_c(x)$ is defined} \newline
  \text{no, }\, \text{otherwise}
  \end{cases}
\]
is computable. Now consider the following algorithm:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ask for a value from the user and store it as X
Access your own code and call it S
if f(S, X) = no
  print &quot;I am not supposed to halt!&quot;
  Halt
if f(S, X) = yes
  print &quot;I am supposed to halt!&quot;
  loop forever
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This program looks at its code, and sees —using the function \(f\)— whether it will halt, and then does exactly the opposite. So it halts if and only if it does not halt! Contradiction.&lt;/p&gt;

&lt;p&gt;Before proving another impossibility result, let we will prove a fixed point version the recursion theorem, sometimes called the second recursion theorem.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; Let \(g\) be a total computable function with a single variable such that \(g(c)\in\mathcal{C}(1)\) for all \(c\in\mathcal{C}(1)\). Then there is a \(S\in\mathcal{C}(1)\) such that \(f_S = f_{g(S)}\).&lt;/p&gt;

&lt;p&gt;Such an \(S\) is called a fixed point of \(g\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof:&lt;/strong&gt; Consider the following code:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ask for a value from the user and store it as X
Access your own code and call it S
Simulate g(S) running on input X
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Let us call this code &lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt;, just like the program itself does. Now for any given &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;, if we run &lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt; on input &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;, we get what &lt;code class=&quot;highlighter-rouge&quot;&gt;g(S)&lt;/code&gt; does on input &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;. But this simply means that on any
&lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;, the codes &lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;g(S)&lt;/code&gt; have the same behavior. So we are done. \(\square\)&lt;/p&gt;

&lt;p&gt;Now we can prove a classical result due to Henry Gordon Rice.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Theorem:&lt;/strong&gt; Let \(\mathcal{A}\) be a decidable subset of \(\mathcal{C}(1)\) such that \(\mathcal{A}\not= \emptyset, \mathcal{C}(1)\). Then there are \(a,b\in\mathcal{C}(1)\) such that \(a\in \mathcal{A}\), \(b\in \mathcal{C}(1)\setminus\mathcal{A}\) and \(f_a = f_b\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof:&lt;/strong&gt; Fix \(a’\in \mathcal{A}\), \(b’\in \mathcal{C}(1)\setminus\mathcal{A}\). Define
\[
  g(c) =
  \begin{cases}
  a’\text{ if } c\in\mathcal{A} \newline
  b’\text{ if } c\not\in\mathcal{A}
  \end{cases}
\]
As \(\mathcal{A}\) is decidable, \(g\) is computable. Let \(c\) be a fixed point of \(g\). Then \(f_c = f_{g(c)}\). Moreover, by construction, \(c\) and \(g(c)\) cannot be both in \(\mathcal{A}\). This finishes the proof. \(\square\)&lt;/p&gt;

&lt;p&gt;This is a remarkable theorem, because it says that there is no decidable semantic property! For instance the following sets are all undecidable:
\[
  \begin{align}
  &amp;amp; \{c\in\mathcal{C}(1) | \text{domain of $f_c$ has 73 elements} \}, \newline
  &amp;amp; \{c\in\mathcal{C}(1) | \text{$f_c$ is total} \}, \newline
  &amp;amp; \{c\in\mathcal{C}(1) | \text{$f_c$ turns an even-length string to an odd-length string} \}, \newline
  &amp;amp; \{c\in\mathcal{C}(1) | \text{$f_c$ is constant} \}, \newline
  &amp;amp; \{c\in\mathcal{C}(1) | \text{$f_c(x)$ has the characters a and 7 for all $x$} \}, \newline
  &amp;amp; \{c\in\mathcal{C}(1) | \text{$f_c(x)$ is longer than $x$ for all $x$} \}, \newline
  &amp;amp; \ldots
  \end{align}
\]&lt;/p&gt;

&lt;p&gt;For our final example, we need a definition. Call an element \(c\in\mathcal{C}(1)\) minimal if for any shorter \(c’\in\mathcal{C}(1)\) we have \(f_c \not= f_{c’}\). It is not difficult to prove that minimality is not a decidable property. I will leave the details to you.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Hint:&lt;/em&gt; Again, suppose that minimality &lt;em&gt;is&lt;/em&gt; decidable and consider the following code:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Ask for a value from the user and store it as X
Access your own code and call it S
Construct a minimal M longer than S and call it W
Simulate W running on input X
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Kolmogorov Complexity (Part 2 of 2)</title>
   <link href="http://localhost:4000/kolmogorov-complexity/2018/06/14/kolmogorov-complexity-2.html"/>
   <updated>2018-06-14T00:00:00+03:00</updated>
   <id>http://localhost:4000/kolmogorov-complexity/2018/06/14/kolmogorov-complexity-2</id>
   <content type="html">&lt;h1 id=&quot;a-crash-course-in-logic&quot;&gt;A Crash Course in Logic&lt;/h1&gt;

&lt;p&gt;In this post we wil apply th Kolmogorov complexity to logic. To be more precise, we will answer to classical questions about foundations
of mathematics. But first, let’s clarify what we mean by foundations.&lt;/p&gt;

&lt;p&gt;For simplicity and definiteness we will stick with set theory (with first order logic) as our foundational theory.
The idea is to express &lt;em&gt;every&lt;/em&gt; notion we use in mathematics in terms of sets using a formal language. Our formal language will have only two
primitive notions, namely equality, which we will denote by \(=\) and membership, which we will denote by \(\in\). Both equality and
membership will be binary relations on sets.&lt;/p&gt;

&lt;p&gt;Other than these two, we will have the following symbols in our language:
\[
  \forall,\, \exists,\, \wedge,\, \vee,\, \neg,\, \rightarrow,\, \leftrightarrow,\, (,\, ),\, x,\, ‘.
\]&lt;/p&gt;

&lt;p&gt;The last symbol, namely \(‘\) is used to obtain an unbounded number of variables from the single variable symbol \(x\)
as follows:
\[
  x’,\, x’’\, x’’’\, x’’’’\, x’’’’’\, x’’’’’’\, \ldots
\]
However, for ease of reading, we will use lower case Roman letters such as \(x,y,z,t,\ldots\) instead of \(x’,\, x’’\, x’’’,\ldots\) The point
here is that even though our alphabet has finitely many symbols, we can talk about infinitely many variables.&lt;/p&gt;

&lt;p&gt;When we talk about sets, we will use only &lt;em&gt;meaningful&lt;/em&gt; or well formed strings in these symbols. I will not define what exactly well formed means but
you can assume that a well formed formula is a string in our symbols which can be parsed according to some grammar. Intuitively, strings like
\[
  \forall )( \rightarrow xx \;\;\text{ or }\;\; ‘‘\vee x \wedge
\]
are not well formed but
\[
  \forall x \forall y (( \forall t (t\in x)\leftrightarrow (t\in y)) \leftrightarrow x = y)
\]
is well formed. Actually this second formula says that two sets are equal if and only if they have the same elements. Note that meaningful
does not mean true. For instance
\[
  \exists x\forall y (y\in x)
\]
is meaningful and says that there is set which contains all sets. However, it is not true in most set theories.&lt;/p&gt;

&lt;p&gt;One important property of well formed formulas is that there is an algorithm which can decide whether an arbitrary string is well formed
or not.&lt;/p&gt;

&lt;p&gt;We want to be able to prove statements about mathematical using our language. After all, this is supposed to be a foundational theory. Since
we have statements, namely the well formed formulas, only two pieces are missing now: assumptions (or axioms) and a notion of proof.&lt;/p&gt;

&lt;p&gt;Again for definiteness, we will work with the axioms of ZFC (Zermalo-Frenkel-Choice) set theory. The actual axioms are not important but you can look
them up if you are curious. The important fact about the axioms is the following: There is an algorithm which can decide whether an arbitrary string
is an axiom.&lt;/p&gt;

&lt;p&gt;Finally a proof of a well formed formula \(varphi\) is simply a sequence of well formed formulas \(\varphi_1,\varphi_2,\ldots,\varphi_n\) such that
\(\varphi_n = \varphi\) and each \(\varphi_i\) is either an axiom or it is obtained from earlier elements in the sequence using deduction rules.
Deduction rules here are rules like “from \(\varphi\rightarrow\psi\) and \(\varphi\) deduce \(\psi\)”. You guessed it, the actual rules are not
important but the important fact about proofs is that there is algorithm which can decide whether an arbitrary sequence of strings is a proof or not.&lt;/p&gt;

&lt;p&gt;A theorem of ZFC is a well formed formula which has a proof. Now you might think that there is an algorithm which can decide whether an arbitrary string is a theorem of ZFC. However, as we will see soon, this is not true. The best you can do is to &lt;em&gt;enumerate&lt;/em&gt; all theorems of ZFC. In other words
there is an algorithm which generates an infinite list containing &lt;em&gt;all&lt;/em&gt; theorems of ZFC. You can probably guess the algorithm: Generate all finite
sequences of well formed formulas in, say, lexicographic ordering. If the sequence happens to be a proof, add the proven formula to the list.&lt;/p&gt;

&lt;p&gt;If you have not heard of recursively enumerable sets before, you might want to think about why this is weaker than having an algorithm which can
decide whether an arbitrary string is a theorem.&lt;/p&gt;

&lt;h1 id=&quot;chaitins-incompleteness-theorem&quot;&gt;Chaitin’s Incompleteness Theorem&lt;/h1&gt;
&lt;p&gt;At this point, you might ask the following question: We have only talked about sets so far but we were looking for a foundational theory
for all of mathematics. Is this really enough? The answer is yes. This may look strange because it seems that there objects in mathematics which are
clearly not sets. For instance \(\pi\) is not a set, it is a number. The trick is that \(pi\), and all mathematical objects for that matter, can
be &lt;em&gt;encoded&lt;/em&gt; as sets.&lt;/p&gt;

&lt;p&gt;Here are a few examples to give you an idea. We can define
\[
  0 = \emptyset,\; 1 = \{0\},\; 2 = \{0,1\},\; 3 = \{0,1,2\},\ldots
\]
So a natural number is the set of smaller natural numbers. For two sets \(x\) and \(y\) we can define
\[
  (x,y) = \{ \{x\}, \{x,y\}\}
\]
and prove that this actually works like an ordered pair (Exercise: Do it!). Once you have ordered pairs, you can have Cartesian products, relations and
functions etc.&lt;/p&gt;

&lt;p&gt;From now on I will assume that we agreed on encodings of all the notions in mathematics as sets. Note that notions like well formed formula, proof and
algorithm are also encoded in this way. So ZFC is capable of talking about Kolmogorov complexity, or even itself.&lt;/p&gt;

&lt;p&gt;Here comes the big theorem of this post. Recall that \(K\) denotes the Kolmogorov complexity.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;There is a constant \(L\) such that for no \(\sigma\), the statement \(K(\sigma) &amp;gt; L\) is a theorem of ZFC.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Suppose not. Then for any natural number \(n\) there is a \(\sigma_n\) such that \(K(\sigma_n)\ &amp;gt; n\) is a theorem of ZFC. This implies that
there is a computable function \(f\) such that for each natural number \(n\) the inequality \(K(f(n)) &amp;gt; n\) is a theorem of ZFC. Indeed,
given any \(n\), using the fact that theorems of ZFC are enumerable, search for a theorem of the form \(K(\sigma) &amp;gt; n\). By assumption this
search will end even though the list is infinite. Define \(f(n)\) to be the first such \(\sigma\) you find. But this is the first step in
the argument which we proves the incomputability of \(K\) in the previous post! You can simply copy the rest of the proof here.&lt;/p&gt;

&lt;p&gt;Let us stop here and look at what we have proved. In ZFC, there is an upper bound on the &lt;em&gt;provable&lt;/em&gt; Kolmogorov complexity. However, there is
no upper bound on Kolmogorov complexity! Therefore there are some true statements of the form \(K(\sigma) &amp;gt; k\) which are not theorems of ZFC.
This means that ZFC is incomplete, in the sense that it cannot capture all true statements. This is Chaitin’s version of Gödel’s first incompleteness
theorem.&lt;/p&gt;

&lt;h1 id=&quot;gödels-second-incompleteness-theorem&quot;&gt;Gödel’s Second Incompleteness Theorem&lt;/h1&gt;
&lt;p&gt;We have been making an implicit assumption about our foundational theory, namely that it was consistent. In other words, we assumed that no
contradiction is a theorem of ZFC. A contradiction is a vacuously false statement like \(\exists x (\neg x = x)\), by the way. This is equivalent to
assuming that not all well formed formulas are theorems of ZFC as everything can be deduced from a contradiction. Obviously, this is a must have
for a foundational theory.&lt;/p&gt;

&lt;p&gt;Recall that ZFC can prove statements about itself. So wouldn’t it be nice to actually have a proof of this assumption in ZFC? This would be proving the consistency of our foundational theory within the theory itself, showing that the theory is self sufficient. Certainly Hilbert wanted to do it.
However his efforts were crashed by, Gödel who proved that no sufficiently rich theory can prove its own consistency. Here sufficiently rich roughly
means strong enough to interpret arithmetic. Now we will give a modern proof of this theorem using Kolmogorov complexity. The proof is due to Shira
Kritchman and Ran Raz.&lt;/p&gt;

&lt;p&gt;Their proof is loosely based on the surprise examination paradox:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In your introduction to logic class, you announce that the students will have an exam next week, but they will not
know the exact day of the exam. So the exam cannot be on Friday because otherwise, the students will know that the exam
will be on Friday after not having an exam on Thursday. Similarly the exam cannot be on Thursday, Wednesday, Tuesday
or Monday.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let \(L\) be as in Chaitin’s theorem. Let \(\ell = c^{L + 1}\) where \(c\geq 2\) is the number of symbols we use in our fixed
programming language. Define
\[
  \mathcal{K} = \{\sigma\, \colon K(\sigma) &amp;gt; L,\, \ell(\sigma) \leq \ell \}
  \;\;\text{ and }\;\;
  k = |\mathcal{K}|
\]
The number \(k\) will roughly correspond to the day on which the exam will take place counted from the end of the week. Clearly \(k\geq 1\) as
there are less than \(\ell\) many programs of size \(L\). Moreover, this observation is also a theorem of ZFC as it is simple counting.&lt;/p&gt;

&lt;p&gt;Now let us prove that \(k \geq 2\). Suppose not. Then \(k=1\). Let \(\sigma_0\) be the unique element of \(\mathcal{K}\). Using the fact that the theorems of ZFC are enumerable, look for proofs of statements of the form \(K(\sigma) \leq L\) for \(\ell(\sigma) \leq \ell\). By assumption, for all \(\sigma\not=\sigma_0\) we have such a proof. So when we have \(\ell - 1\) proofs, the remaining string should be \(\sigma_0\) which has
to have complexity greater than \(L\). But we just proved, in ZFC, that a certain string has complexity greater than \(L\). This contradicts the choice of \(L\).&lt;/p&gt;

&lt;p&gt;Now let us prove that \(k \geq 3\). Suppose not. Then \(k = 2\). Let \(\sigma_0, \sigma_1\) be the only elements of \(\mathcal{K}\). Using the
fact that the theorems of ZFC are enumerable, look for proofs of statements of the form \(K(\sigma) \leq L\) for \(\ell(\sigma) \leq \ell\). By assumption, for all \(\sigma\not=\sigma_0, \sigma_1\) we have such a proof. So when we have \(\ell - 2\) proofs, the remaining two strings should
be \(\sigma_0\) and \(\sigma_1 \) which have to have complexity greater than \(L\). But we just proved, in ZFC, that a certain string has complexity greater than \(L\). This contradicts the choice of \(L\).&lt;/p&gt;

&lt;p&gt;Now let us prove that \(m \geq 4\)\ldots Well, you see the pattern. Using this method we can exhaust all possible values for \(k\) and obtain a
contradiction. So assuming that ZFC can prove its consistency leads to a contradiction.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Kolmogorov Complexity (Part 1 of 2)</title>
   <link href="http://localhost:4000/kolmogorov-complexity/2018/05/21/kolmogorov-complexity-1.html"/>
   <updated>2018-05-21T00:00:00+03:00</updated>
   <id>http://localhost:4000/kolmogorov-complexity/2018/05/21/kolmogorov-complexity-1</id>
   <content type="html">&lt;h1 id=&quot;a-mandatory-example&quot;&gt;A Mandatory Example&lt;/h1&gt;

&lt;p&gt;Consider the following two binary strings:
\begin{align}
&amp;amp;\texttt{0101010101010101010101010101010},\newline
&amp;amp;\texttt{1100100100001111110110101010001}.
\end{align}&lt;/p&gt;

&lt;p&gt;Which one do you think is easier to remember? Most people would say that the first one, because
there is an obvious and simple rule/method to generate it. So, instead of remembering the string,
we can remember the rule. One can also say that the first string is simple while the second one is
complex. Kolmogorov complexity is a quantified version of this intuitive notion.&lt;/p&gt;

&lt;p&gt;Let us semi-formalize it. First let us fix a Turing complete programming language. I will not define what a programming
language &lt;em&gt;is&lt;/em&gt; or &lt;em&gt;should be&lt;/em&gt; and, frankly, be somewhat vague about it. Hence the prefix &lt;em&gt;semi&lt;/em&gt; in front of
&lt;em&gt;formalize&lt;/em&gt;. Though I will make a few assumptions. Programs in our programming language will be strings
from from a fixed alphabet \(\mathcal{L}\), say, containing ASCII or UTF-8. I will also assume that each program
accepts strings from \(\mathcal{L}\) as input and produce strings from \(\mathcal{L}\) as output. So,
in particular, we can give a program to another program as input or a program may produce a program. For ease
of reading, I will use \(\texttt{this font}\) when writing a string from \(\mathcal{L}\).&lt;/p&gt;

&lt;p&gt;One technical assumption which will be important later is that our programs will use decimal representation
for natural numbers. Actually pretty much any positional system would do, but for the sake of definiteness
I will stick with decimal.&lt;/p&gt;

&lt;p&gt;When I write a program, I will use some sort of pseudocode hoping that there is no ambiguity. Also I will
not exclude partial programs which corresponds do partial functions. For instance
\begin{align}
&amp;amp;\texttt{accept x as input}\newline
&amp;amp;\texttt{while 1 == 1}\newline
&amp;amp;\;\;\;\texttt{do nothing}\newline
&amp;amp;\texttt{return x}
\end{align}
is a valid program even though it does not produce any result as it is always stuck in the while loop.&lt;/p&gt;

&lt;p&gt;Now we can define the Kolmogorov complexity of a string from \(\mathcal{L}\): Let \(\sigma\) be a string
from \(\mathcal{L}\). The Kolmogorov complexity of \(\sigma\) is the length of the shortest program which
generates \(\sigma\) on any input. It is denoted by \(K(\sigma)\).&lt;/p&gt;

&lt;h1 id=&quot;how-canonical-is-this-definition&quot;&gt;How canonical is this definition?&lt;/h1&gt;

&lt;p&gt;The definition seems very intuitive, especially after the mandatory example. However, there is something fishy here.
We made several arbitrary choices yet we called \(K(\sigma)\) &lt;em&gt;the&lt;/em&gt; Kolmogorov complexity of \(\sigma\). It should
be clear that it is easier to generate certain strings in some languages than others. Indeed, the second string in our
example is just the first few digits of the binary expansion of \(\pi\) so it can be easier to generate in a language
designed for numerical computations.&lt;/p&gt;

&lt;p&gt;Even worse, for any string \(\sigma\), we can very well imagine a programming language which has \(\sigma\) as a built-in
constant. Thus the Kolmogorov complexity of a single string seems to very heavily depend on our language of choice. So
does this mean that our definition of \(K\) is arbitrary? What happens if we change our programming language?&lt;/p&gt;

&lt;p&gt;Let us consider two notions of complexity \(K_1\), \(K_2\) corresponding
to two different programming languages \(L_1\) and \(L_2\), respectively. Since \(L_1\) is Turing complete, we can write a
&lt;em&gt;compiler&lt;/em&gt; for \(L_2\) in \(L_1\). In other words, \(L_1\) can simulate \(L_2\). Let \(\sigma\) be a string and
let \(n=K_2(\sigma)\). Then there is a program \(p\) in the language \(L_2\) which witnesses the fact that \(n=K_2(\sigma)\).
That is, \(p\) has length \(n\) and \(p\) generates \(\sigma\). Now consider the following (description of a) program in \(L_1\):
Simulate \(p\). The length of this program will be \(n + c\) for some \(c\) because the program contains the string \(p\) and
\(p\) has length \(n\). The part corresponding to \(c\) is the part that simulates \(L_2\) and it does not depend on \(\sigma\).
By construction, “Simulate \(p\)” generates \(\sigma\), thus
\[
  K_1(\sigma)\leq n + c = K_2(\sigma) + c.
\]
We proved that there is a constant \(c\) such that \(K_1(\sigma)\leq K_2(\sigma) + c\) for all \(\sigma\). By symmetry,
there is a \(c’\) such that \(K_2(\sigma)\leq K_1(\sigma) + c’\) for all \(\sigma\). Combining these two we obtain
\[
  |K_1(\sigma) - K_2(\sigma)| &amp;lt; {\rm max}\{c, c’\}.
\]
This shows that if we consider an infinite family of strings and consider the asymptotic behavior of Kolmogorov complexity
on that family, then the programming language we choose does not matter. Obviously, this does not imply that this asymptotic
behavior is easy to determine.&lt;/p&gt;

&lt;p&gt;From now on we will stick with a fixed but not explicitly determined choice of language and denote the complexity function
given by that language by \(K\).&lt;/p&gt;

&lt;p&gt;At this point I would compute the Kolmogorov complexity of some concrete strings (or infinite families of strings) but it is tricky.
We can always give an upper bound for Kolmogorov complexity by explicitly constructing a program and measuring its length
but the tricky part is to show that no shorter program generates the same string. Actually, the problem is so difficult that
there is no general solution. To put it more concretely, the function  \(K\) is not computable. The aim of this post is to
give a proof of this result.&lt;/p&gt;

&lt;h1 id=&quot;berry-paradox&quot;&gt;Berry Paradox&lt;/h1&gt;

&lt;p&gt;Before moving on to the actual proof, let us see the underlying idea of the proof in a linguistic context. Let us consider the following
description of a number:&lt;/p&gt;

&lt;p&gt;\begin{align}
&amp;amp;\texttt{the least natural number that cannot be}\newline
&amp;amp;\texttt{described in English by less than 88 characters}
\end{align}&lt;/p&gt;

&lt;p&gt;Let \(n\) be the natural number defined by this description. But this description itself has only 87 characters, counting
spaces and digits, so \(n\) has a description with only 87 characters. Contradiction! This argument is known as the Berry
paradox. I will not go into a linguistic or philosophical debate here, there is already a substantial body of literature on the topic.&lt;/p&gt;

&lt;p&gt;Now note that if we start with the following description, we cannot really say much about the number it describes,
nevertheless, we do not end up with a paradox either:&lt;/p&gt;

&lt;p&gt;\begin{align}
&amp;amp;\texttt{the least natural number that cannot be}\newline
&amp;amp;\texttt{described in English by less than 75 characters}
\end{align}&lt;/p&gt;

&lt;p&gt;Thus the number in the description is not arbitrary. Here is a natural question: What values of \(n\) give rise to the Berry paradox?
To answer that question we will make the number \(n\) a parameter. For a natural number \(n\) let \(\ulcorner n \urcorner\) be the
decimal expression of \(n\) as a string. So, for instance \(\ulcorner 234 \urcorner = \texttt{234}\), \(\ulcorner 0 \urcorner = \texttt{0}\),
etc. Now define \(\Delta(n)\) be&lt;/p&gt;

&lt;p&gt;\begin{align}
&amp;amp;\texttt{the least natural number that cannot be}\newline
&amp;amp;\texttt{described in English by less than $\ulcorner n \urcorner$ characters}
\end{align}&lt;/p&gt;

&lt;p&gt;Clearly a positive natural number \(n\) gives rise to the Berry paradox if \(\ell(\Delta(n)) &amp;lt; n\) where \(\ell(\sigma)\)
denotes the length of \(\sigma\). Note that
\[
  \ell(\Delta(n)) = 85 + \ell(\ulcorner n \urcorner) = 85 + 1 + \lfloor \log_{10} n \rfloor.
\]
because \(\ell(\ulcorner n \urcorner)\) is simply the number of digits of \(n\). So the inequality we should solve is
\[
  86 + \lfloor \log_{10} n  \rfloor &amp;lt; n.
\]
We can of course find the exact solution set of this inequality but what is more interesting is that we can immediately tell
that there are solutions. The reason is that the left hand side grows logartihmically and the right hand side grows linearly and hence
the right hand side should dominate the left hand side for all sufficiently large values of \(n\). Even better, if we change the
phrasing of the condition or express it in a different language such as  french, we would need to solve the equation \(c + \lfloor \log_{10} n  \rfloor &amp;lt; n\) for some constant \(c\) and, by the same argument, we would have a solution. Thus the Berry paradox is about exploiting the fact that our measure
of complexity can be referred to in a not so complex way. Note that if we were to use the unary system instead of decimal, that is if we expressed \(n\) as \(n\)-many \(\texttt{1}\)’s, then we would have \(\ell(\Delta(n))=c + n\) for some \(n\) and the Berry paradox would not come up.&lt;/p&gt;

&lt;h1 id=&quot;an-incomputability-result&quot;&gt;An Incomputability Result&lt;/h1&gt;
&lt;p&gt;Here is the theorem we: There is no computer program which takes \(\sigma\) as input and produces \(\ulcorner K(\sigma) \urcorner\)
as output. For the proof, we will mimic the Berry paradox.&lt;/p&gt;

&lt;p&gt;Suppose that there &lt;em&gt;is&lt;/em&gt; such a program \(p\). We will obtain a contradiction. Consider the following program:
\begin{align}
&amp;amp;\texttt{accept n as input}\newline
&amp;amp;\texttt{if n does not represent a natural number then halt}\newline
&amp;amp;\texttt{set x to be the first string in alphabetical order}\newline
&amp;amp;\texttt{while the Kolmogorov complexity of x is less than n}\newline
&amp;amp;\;\;\;\texttt{replace x by the next string in alphabetical order}\newline
&amp;amp;\texttt{return x}
\end{align}&lt;/p&gt;

&lt;p&gt;Note that we use \(p\) to check the condition in the while loop. Also note that the while loop is never stuck because
there is no bound on the Kolmogorov complexity. So this program produces a string of complexity grater than \(n\) if its
input is \(\ulcorner n \urcorner\).&lt;/p&gt;

&lt;p&gt;Now for each \(n\) we can construct a program \(\tau_n\) as follows:&lt;/p&gt;

&lt;p&gt;\begin{align}
&amp;amp;\texttt{accept u as input}\newline
&amp;amp;\texttt{set x to be the first string in alphabetical order}\newline
&amp;amp;\texttt{while the Kolmogorov complexity of x is less than $\ulcorner n\urcorner$}\newline
&amp;amp;\;\;\;\texttt{replace x by the next string in alphabetical order}\newline
&amp;amp;\texttt{return x}
\end{align}&lt;/p&gt;

&lt;p&gt;Clearly \(\tau_n\) ignores the input and behaves like \(\tau\) with input \(\ulcorner n\urcorner\). Moreover
\(\ell(\tau_n) = \lfloor\log_{10}(n)\rfloor + c\) for some constant \(c\). Thus, for a sufficiently large \(k\) we have \(\ell(\tau_k) &amp;lt; k\).&lt;/p&gt;

&lt;p&gt;Let \(\omega\) be the string produced by \(\tau\) on an input \(\ulcorner k \urcorner\) satisfying \(\ell(\tau_k) &amp;lt; k\). Here comes the finishing blow: By the construction of \(\tau\), we have \(K(\omega)\geq k\). On the other hand \(\tau_k\) also produces \(\omega\) (on any input) therefore we must have \(K(\omega)\leq \ell(\tau_k)\). But these two inequalities imply that \(k \leq \ell(\tau_k)\). Contradiction!&lt;/p&gt;

&lt;p&gt;Let us summarize what we did: We defined a not exactly canonical notion of complexity which is impossible to compute in practice. So what can we even do with it? Well, mathematical logic of course! This will be the topic of the forthcoming post on Kolmogorov complexity.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Curry-Howard Correspondence From Scratch (Part 2 of 2)</title>
   <link href="http://localhost:4000/curry-howard/2018/05/14/curry-howard-from-scratch-2.html"/>
   <updated>2018-05-14T00:00:00+03:00</updated>
   <id>http://localhost:4000/curry-howard/2018/05/14/curry-howard-from-scratch-2</id>
   <content type="html">&lt;h1 id=&quot;simply-typed-lambda-calculus&quot;&gt;Simply Typed Lambda Calculus&lt;/h1&gt;

&lt;p&gt;In the first post we constructed a formal theory of propositions but left the
notion of &lt;em&gt;naming a specific element&lt;/em&gt; from a function set vague. Now we are going to fix that.&lt;/p&gt;

&lt;p&gt;Our central notion will be that of a &lt;em&gt;lambda term&lt;/em&gt;. As we want to define a formal theory we will
not define what a lambda term is and focus on how to construct new lambda terms from old ones. Intuitively
though, we will think of lambda terms as function prototypes.&lt;/p&gt;

&lt;p&gt;First we need variables. We will assume that we have an infinite set of variables and denote
variables by lower case letters from the Latin alphabet. Each variable will also be a lambda term.
Other than that, there will be two ways to construct a lambda term. First, if \(M\) and \(N\) are
lambda terms then so is \(MN\). We will think of \(MN\) as \(M\) applied to \(N\). Second,
if \(x\) is a variable and \(M\) is a lambda term than so is \(\lambda x.M\). Intuitively
\(\lambda x.M\) will mean \(x\mapsto M(x)\). This will be clearer when we start using lambda terms.&lt;/p&gt;

&lt;p&gt;Let us look at a few examples. The following are all lambda terms constructed using variables only:
\[
  x,\; xy,\; xx,\; x(yz),\; (xy)z,\; (xx)x,\; (xy)(x(yz)).
\]
Of course we can also use \(\lambda\):
\[
  \lambda x.x,\; \lambda y. y,\; \lambda x. y,\; \lambda y. (\lambda x. (yx))),\;
  (\lambda x. (xy))(\lambda y. x).
\]
To reduce the number of brackets we will give application higher priority than \(\lambda\).
So, for instance, the expression \(\lambda x. yz\) will stand for \(\lambda x. (yz)\) rather than
\((\lambda x. y)z\).&lt;/p&gt;

&lt;p&gt;Now let us define when two lambda terms are equal. Since we think of \(\lambda x.M\) as a function
mapping \(x\) to \(M\), we see \(\lambda x.x\) as some kind of identity function. However, under
this interpretation, there should not be a difference between \(\lambda x.x\) and \(\lambda y.y\).
More generally there should not be a difference between \(x\mapsto M(x)\) and \(y\mapsto M(y)\).
Therefore we want
\[
  \lambda x. x  = \lambda y. y = \lambda z. z = \ldots
\]
Maybe slightly more interestingly, we also want
\begin{align}
\lambda z. ((\lambda x.x)(\lambda y.yz))   &amp;amp;=
\lambda u. ((\lambda x.x)(\lambda y.yu))\newline &amp;amp;=
\lambda z. ((\lambda x.x)(\lambda u.uz))\newline &amp;amp;=
\lambda z. ((\lambda z.z)(\lambda u.uz))\newline &amp;amp;=
\ldots
\end{align}&lt;/p&gt;

&lt;p&gt;We will call this &lt;em&gt;harmless renaming of variables&lt;/em&gt; \(\alpha\)-equivalence. One can define \(\alpha\)-equivalence
formally but it is slightly messy. Therefore we will not do it here and instead adopt a convention: In a \(\lambda\)
term, each \(\lambda\) will use a different variable. So, for instance, we will avoid using the last lambda term
in the list above since \(\lambda z\) appears twice in it.&lt;/p&gt;

&lt;p&gt;Now comes the more interesting properties of equality. We define
\[
  (\lambda x. M)N = M[x:= N].
\]
Here \(M\) is a lambda term and \( M[x:= N]\) stands for the lambda term obtained from \(M\) by replacing each
occurrence of \(x\) by \(N\). For instance
\[
  (\lambda x. x) N = x[x := N] = N.
\]
So \(\lambda x. x\) does behave like identity. Here is another example:
\begin{align}
(\lambda y. (\lambda x. yx))(\lambda z. z)  &amp;amp;= (\lambda x. yx)[y:=\lambda z. z] \newline
&amp;amp;= \lambda x. ((\lambda z.z)x) \newline
&amp;amp;= \lambda x. (z[z:=x]) \newline
&amp;amp;= \lambda x. x.
\end{align}&lt;/p&gt;

&lt;p&gt;Finally, let us express the functions \(C\) and \(E\) we defined in the previous post as lambda terms. By definition
\(C_x(y)=x\) so \(C_x = \lambda y. x\). If we view \(C_x\)  as a function of \(x\) then we get
\[
  C = \lambda x. (\lambda y. x).
\]
Again by definition we have \(E_x(f) = f(x)\) so \(E_x = \lambda f. f x\). Therefore
\[
  E = \lambda x. (\lambda f. f x).
\]&lt;/p&gt;

&lt;p&gt;What we defined so far is called the &lt;em&gt;untyped lambda calculus&lt;/em&gt;. Even though it gives us a formal theory of
functions, it is not enough for our purposes as we also need function sets. To be able to talk about some
sort of function sets, we will introduce the notion of &lt;em&gt;type&lt;/em&gt; into our theory.&lt;/p&gt;

&lt;p&gt;The definition of a type is going to be very simple: if \(\alpha\) and  \(\beta\) are types then so is
\(\alpha\to\beta\). Note that, formally speaking, there is no difference between types and propositions we defined in the
previous post. On the other hand, while a proposition has the connotation of a judgement, a type will be
more like function sets.&lt;/p&gt;

&lt;p&gt;Now we will define our typing relation between lambda terms and types. If a lambda term \(M\) is related to the type
\(\tau\) then we will say that \(M\) is of type \(\tau\) and denote it by \(M\colon\tau\). We will call
a statement like \(M\colon\tau\) a type assignment. A context will simply be a set of type assignments. Our typing system
will consist of rules, which given a context, allows us to derive type assignments. If a context \(\Gamma\) allows us
to derive an assignment \(M\colon\tau\) we will denote it by \(\Gamma\vdash M\colon\tau\). Note that we are overloading
the symbol \(\vdash\) here.&lt;/p&gt;

&lt;p&gt;Here is the first rule. Let \(\Gamma\) be a context, then
\[
  \Gamma,x\colon\tau\vdash x\colon\tau\
\]
So, if the type of variable \(x\) is \(\tau\) in a given context, then we can derive the assignment \(x\colon\tau\)
in that context. Let us call this the rule \(A^\to\).&lt;/p&gt;

&lt;p&gt;Here is the second rule:
\[
  \text{if }\;\,
  \Gamma\vdash N:\sigma\;\,
  \text{ and }\;\,\
  \Gamma\vdash M:\sigma\to\tau\;\;
  \text{ then }\;\;\Gamma\vdash MN:\tau.
\]
So if \(M\) is a function which maps objects of type \(\alpha\) to objects of type \(\beta\) and
\(N\) is of type \(\alpha\) then \(M\) applied to \(N\) should be of type \(\beta\). Let us call this
the rule \(B^\to\).&lt;/p&gt;

&lt;p&gt;Finally,
\[
  \text{if }\;\;\;
  \Gamma,x:\tau\vdash M:\sigma \;\;\;
  \text{ then }\;\;\;
  \Gamma\vdash \lambda x. M:\tau\to\sigma.
\]
If \(x\) is of type \(\tau\) then any lambda term starting with \(\lambda x.\) should be a function
from \(\tau\) to somewhere. As \(M\) is of type \(\sigma\), obviously we should have \(\lambda x. M:\tau\to\sigma\).
Let us call this the rule \(C^\to\).&lt;/p&gt;

&lt;p&gt;The system we constructed with rules \(A^\to\), \(B^\to\) and \(C^\to\) is called the simply typed
lambda calculus in the style of Church and sometimes denoted by \(\lambda^\to\). At this point you might
want to compare \({\rm IP}(\to)\) and \(\lambda^\to\), especially the rules \(A\), \(B\), \(C\)
and \(A^\to\), \(B^\to\), \(C^\to\).&lt;/p&gt;

&lt;p&gt;Now we can give a precise definition of naming a specific element from a function set. Let \(A\) be a function
set as we used in the previous post. Formally, we can view \(A\) as a type, say \(\tau\). If there is a
lambda term \(M\) such that \(\vdash M\colon\tau\) then we say that one can name a specific function from
\(A\), namely \(M\).&lt;/p&gt;

&lt;p&gt;As an example consider the lambda term \(\lambda x.(\lambda f.f x)\). Recall that it corresponds to
\(x\mapsto E_x\). Let \(\Gamma=\{x:\alpha,\,f:\alpha\to\beta\}\). Then, by the rule \(A^\to\), we
get
\[
  \Gamma\vdash x\colon\alpha \;\;
  \text{ and }\;\;
  \Gamma\vdash f\colon\alpha\to\beta.
\]
And from these, together with rule \(B^\to\) we obtain \(\Gamma\vdash f x: \beta\). Finally, applying
the rule \(C^\to\) twice we derive
\[
  \vdash \lambda x. (\lambda f. f x) : \alpha\to((\alpha\to\beta)\to\beta).
\]&lt;/p&gt;

&lt;h1 id=&quot;finally-the-curry-howard-correspondence&quot;&gt;Finally, The Curry-Howard Correspondence&lt;/h1&gt;
&lt;p&gt;We need one final definition before we can express the Curry-Howard correspondence between \({\rm IP}(\to)\) and
\(\lambda^\to\) formally.&lt;/p&gt;

&lt;p&gt;Let \(\Gamma\) be a context. Define
\[
  |\Gamma| =\{\tau \colon \text{ there is a variable $x$ such that } x : \tau\in\Gamma\}.
\]
Note that \(|\Gamma|\) consists of types/propositions. In other words, \(|\Gamma|\) is an assumption set. is the set of variables
appearing in \(\Gamma\).&lt;/p&gt;

&lt;p&gt;Finally, I present you the Curry-Howard Correspondence for \({\rm IP}(\to)\) and \(\lambda^\to\):&lt;/p&gt;

&lt;p&gt;If \(\Gamma\vdash M:\varphi\) then \(|\Gamma|\vdash\varphi\). Conversely, if \(|\Gamma|\vdash\varphi\) then
there is a lambda term \(M\) such that \(\Delta\vdash M:\varphi\) where \(\Delta=\{x_\psi:\psi\;|\; \psi\in\Gamma\}\).
To paraphrase it as a slogan, if we view types as propositions, provable propositions are precisely the types of
lambda terms.&lt;/p&gt;

&lt;p&gt;Even this modest version of the Curry-Howard correspondence is beautiful and surprising. One wonders if it is possible to
generalize it. Actually, there is a very natural direction of generalization. We know that \({\rm IP}(\to)\) is a restricted version
of a more general logic, namely the full intuitionistic propositional logic. So we can try to generalize the theorem
to different logics. However, it is not clear how to generalize \(\lambda^\to\), especially if you have not seen lambda calculus
before. The idea is that \(\lambda^\to\) is a programming language and in order to generalize the Curry-Howard correspondence, we need
to find/invent different programming languages with different type systems.&lt;/p&gt;

&lt;p&gt;First, let us clarify what we mean by \(\lambda^\to\) is a programming language. Let us fix a type \(\tau\) and define
\(\texttt{Nat}=(\tau\to\tau)\to(\tau\to\tau)\). As the name suggests, \(\texttt{Nat}\) will be the set of natural
numbers. For lambda terms \(M\) and \(N\) let us make the following recursive definition: \(M^0N = N\) and
\(M^{n+1}N=M(M^nN)\). So \(M^nN\) is \(M\) applied to \(N\), \(n\)-times. The Church encoding
of a natural number \(n\) is
\[
  \ulcorner n \urcorner = \lambda s. (\lambda z. s^n z).
\]
As you can check easily, \(\vdash \ulcorner n \urcorner : \texttt{Nat}\). We can also define basic operations on \(\texttt{Nat}\).
For instance if
\[
  A_+ = \lambda x. (\lambda y. (\lambda s. (\lambda z. (xs)((ys)z))))
\]
then we have \(\vdash A_+ : \texttt{Nat} \to (\texttt{Nat} \to \texttt{Nat})\) and for all natural number \(m\) and \(n\) the
equality \((A_+\ulcorner m \urcorner )\ulcorner n \urcorner =\ulcorner m + n \urcorner \) holds. Therefore we can interpret
\(A_+\) as a program which adds numbers. As an exercise you might want to define a computer program which does multiplication.&lt;/p&gt;

&lt;p&gt;One can even define booleans in \(\lambda^\to\). Let \({\bf T}=\lambda y. (\lambda x . x)\) and \({\bf F}=\lambda y. (\lambda x . y)\).
If we interpret \({\bf T}\) as true and \({\bf F}\) as false then \((BP)Q\) acts like
\[
  {\bf if}\; B\; {\bf then}\; P \;{\bf else}\; Q
\]
if \(B\) is \({\bf T}\) of \({\bf F}\). These may look like ad-hoc ideas but lambda terms (without their types) is actually a
universal way of writing programs. This is the topic of another post, though.&lt;/p&gt;

&lt;p&gt;Now back to the original question (with a finer statement): Can we find/invent a different programming language whose typing rules
corresponds to a logic in such a way that proving a proposition/type in that logic corresponds to writing a program of that
proposition/type? The answer is amazingly yes!&lt;/p&gt;

&lt;p&gt;For a very simple example, consider the &lt;em&gt;and&lt;/em&gt; operation on propositions.
The type construction rule corresponding to logical &lt;em&gt;and&lt;/em&gt; should be pairing, also known as the Cartesian product. Because, using the analogy
in the first post, naming an element from a set \(X\) &lt;em&gt;and&lt;/em&gt;  a set \(Y\) is the same as naming an element from \(X\times Y\).
In a similar fashion, &lt;em&gt;or&lt;/em&gt; corresponds to sum types. One can also consider logics with quantifiers, modalities or linear logics etc. and they
all come with their corresponding programming languages. Moreover the properties of the type system viewed as a logic are reflected as
programming language features such as polymorphism, staging, resource awareness etc. So what we covered in these two posts is just the tip
of the iceberg.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Curry-Howard Correspondence From Scratch (Part 1 of 2)</title>
   <link href="http://localhost:4000/curry-howard/2018/05/05/curry-howard-from-scratch-1.html"/>
   <updated>2018-05-05T00:00:00+03:00</updated>
   <id>http://localhost:4000/curry-howard/2018/05/05/curry-howard-from-scratch-1</id>
   <content type="html">&lt;h1 id=&quot;function-sets&quot;&gt;Function Sets&lt;/h1&gt;

&lt;p&gt;Suppose we have two sets \(X\) and \(Y\). Can we name a function from \(X\) to \(Y\) without
using what \(X\) or \(Y\) is? Obviously if \(Y\) is empty and \(X\) is not empty then this is not possible
as there is no function from a nonempty set to the empty set. So let us suppose \(X\) and \(Y\) are nonempty
for the moment. Now there &lt;em&gt;are&lt;/em&gt; functions from \(X\) to \(Y\). For instance, for every element \(y\in Y\),
there is the constant function which takes the value \(y\). Bu this does not count because the problem is to &lt;em&gt;name&lt;/em&gt; a
particular function, not to prove the existence of such functions. It looks difficult. Actually, in a sense
which we will define later, the answer is that we cannot name such a function. Considering the fact that we do not
know anything about \(X\)  and \(Y\) this is hardly surprising.&lt;/p&gt;

&lt;p&gt;On the other hand, if we take \(X=Y\) then it is possible to name such a function: the identity function. Since
the identity function maps each element to itself, we do not need to know anything about \(X\). Frankly, this
does not seem like an interesting observation, either. However, as we consider more complex examples, the situation will
change dramatically.&lt;/p&gt;

&lt;p&gt;Let us introduce some notation. For sets \(X\) and \(Y\), we will denote the set of functions from \(X\) to \(Y\)
by \(X\to Y\). In this notation \(f \in X\to Y\) and \(f \colon X \to Y\) have the same meaning. For instance,
if we denote the identity function on \(X\) by \(1_X\), then we have \(1_X \in X\to X\).&lt;/p&gt;

&lt;p&gt;Now let us consider the following question: Can we name a function from the set
\[
  X \to (Y \to X) ?
\]
What we need to find is a function, which, given an element of \(X\), produces a function from \(Y\) to \(X\). After
a moments thought, it is easy to come up with the function \(x\mapsto C_x\) where \(C_x(y)=x\) for all \(y\in Y\). In
other words, we can send \(x\) to the constant function which only attains the value \(x\).&lt;/p&gt;

&lt;p&gt;In a similar way, one can easily see that
\[
  x\mapsto 1_Y \in X \to (Y \to Y).
\]
However, it seems that the problem has no solution for the sets
\[
  X \to (X \to Y) \;\;\;\text{ and }\;\;\; (X \to Y) \to Y
\]&lt;/p&gt;

&lt;p&gt;We can consider even more complex examples. For instance
\[
  x\mapsto E_x \in X \to ((X \to Y ) \to Y).
\]
where \(E_x\) is the ‘‘evaluation at \(x\)’’ function, that is \(E_x(f) = f(x)\).
Yet the problem has no solution for the set
\[
  X \to ((Y \to X) \to Y).
\]&lt;/p&gt;

&lt;p&gt;As an exercise, you might want to name an element from the set
\[
  (X \to (Y \to Z)) \to ((X \to Y) \to (X \to Z)).
\]&lt;/p&gt;

&lt;p&gt;After seeing all these examples, we have a somewhat vague but very natural questions:
From which sets can we name specific elements? We will give a rather surprising answer to this question.&lt;/p&gt;

&lt;h1 id=&quot;propositional-calculus-with-only-implication&quot;&gt;Propositional Calculus with only Implication&lt;/h1&gt;
&lt;p&gt;After function sets, the title may remind you of the Monty Python Movie &lt;em&gt;And Now for Something Completely Different&lt;/em&gt;
but bear with me. I promise this is going somewhere.&lt;/p&gt;

&lt;p&gt;In this section we will develop a modest theory of propositions. We are not going to define &lt;em&gt;what&lt;/em&gt; a proposition is,
but intuitively, we will think of propositions as judgments. The central notion in our theory will be that of proof,
or rather the “proves” relation which we will denote by \(\vdash\). The proves relation will be a relation
between proposition sets, which we will call assumption sets, and propositions. If \(\Gamma\) is a set of
propositions and \(p\) is a proposition we will write \(\Gamma\vdash p\) to denote \(\Gamma\) proves \(p\).&lt;/p&gt;

&lt;p&gt;Now we will list the properties we want \(\vdash\) to satisfy. These properties will be our deduction rules. For
ease of notation we will abbreviate \(\Gamma\cup\{p\}\) as  \(\Gamma,p\) and \(\Gamma\cup\{p,q\}\) as \(\Gamma,p,q\).
We will also write \(\vdash p\) instead of \(\emptyset\vdash p\).&lt;/p&gt;

&lt;p&gt;Our first deduction rule is trivial: We can prove a proposition if it is among our assumptions. Formally,
\[
  \Gamma, p\vdash p.
\]
We will call this the rule \(A\).&lt;/p&gt;

&lt;p&gt;For the other deduction rules, we need to define how we can construct new propositions from old ones. There are
several ways to do it. We can use conjunctions, disjunctions, negations, implications etc. For the sake of this post, we
will only work with implication. If \(p\) and \(q\) are two propositions then we define a new proposition \(p\to q\)
and read it as “\(p\) implies \(q\)”. Obviously this is a completely formal definition.&lt;/p&gt;

&lt;p&gt;Now we can introduce more deduction rules. The next rule is the famous &lt;em&gt;modus ponens&lt;/em&gt; rule. It says
if one can prove \(p\) and \(p\to q\) from an assumption set \(\Gamma\) then we can also prove \(q\) from \(\Gamma\).
More formally we have
\[
  \text{if }\;\;\;\Gamma\vdash p\;\;\;\text{ and }\;\;\;\Gamma\vdash p\to q
  \;\;\;\text{ then }\;\;\;\Gamma\vdash q.
\]
We will call this the rule \(B\).&lt;/p&gt;

&lt;p&gt;Our final rule is kind of a dual version of modus ponens. It says that if one can prove \(q\) from \(\Gamma\) together
with \(p\) then using only \(\Gamma\) one can prove \(p\to q\). More formally
\[
  \text{if }\;\;\;\Gamma,p\vdash q\;\;\;\text{ then }\;\;\;\Gamma\vdash p\to q.
\]
We will call this the rule \(C\).&lt;/p&gt;

&lt;p&gt;Our propositional logic with the rules \(A\), \(B\) and \(C\) is called the implicational fragment of the intuitionistic propositional
logic and sometimes denoted by \({\rm IP}(\to)\). So what can we deduce in \({\rm IP}(\to)\)? Let us look at a few examples.&lt;/p&gt;

&lt;p&gt;First of all, by \(A\), we have \(p\vdash p\). So, by \(C\), we deduce \(\vdash p\to p\). On the other hand we should not have
\(\vdash p\to q\) because it is absurd to expect an arbitrary proposition to imply an arbitrary proposition. Actually
it is not difficult to prove that we cannot deduce \(\vdash p\to q\) in \({\rm IP}(\to)\) but we will mostly rely on intuitive arguments.&lt;/p&gt;

&lt;p&gt;Here is another example. By \(A\), we have \(p,q\vdash p\). By \(C\), we deduce \(p\vdash q\to p\). Using \(C\) once more we obtain
\(\vdash p\to (q\to p)\). If we start with \(p,q\vdash q\) in the previous argument we obtain \(\vdash p\to (q\to q)\).
On the other hand we should not be able to deduce \(\vdash p \to (p\to q)\). Because assuming \(p\) holds, we cannot
say that \(p\) implies an arbitrary \(y\).&lt;/p&gt;

&lt;p&gt;Note that we have not used the rule \(B\) yet. So let us look at an example involving that rule. Let
\[
  \Gamma=\{p,p\to q\}.
\]
First of all, by \(A\), we have \(\Gamma\vdash p\) and \(\Gamma\vdash p\to q\). Thus, by \(B\), we deduce \(\Gamma\vdash q\).
Now using the rule \(C\) twice we get
\[
  \vdash  p \to ((p \to q) \to q).
\]&lt;/p&gt;

&lt;p&gt;As an exercise, prove that
\[
  \vdash
   (p \to (q \to r)) \to ((p \to q) \to (p \to r)).
\]&lt;/p&gt;

&lt;p&gt;Now let us list the propositions we were able to prove with an empty assumption set:&lt;/p&gt;

&lt;p&gt;\begin{align}
&amp;amp; p \to p, \newline
&amp;amp; p \to (q \to p), \newline
&amp;amp; p \to (q \to q), \newline
&amp;amp; p \to ((p \to q) \to q), \newline
&amp;amp; (p \to (q \to r)) \to ((p \to q) \to (p \to r)).
\end{align}&lt;/p&gt;

&lt;p&gt;Let us also list all the function sets from which we were able to name specific elements:
\begin{align}
&amp;amp; X \to X, \newline
&amp;amp; X \to (Y \to X), \newline
&amp;amp; X \to (Y \to Y), \newline
&amp;amp; X \to ((X \to Y) \to Y), \newline
&amp;amp; (X \to (Y \to Z)) \to ((X \to Y) \to (X \to Z)).
\end{align}&lt;/p&gt;

&lt;p&gt;Either we have a strange coincidence in our hands or we just observed a nontrivial relation between functions and
propositions. In the next post, we will see that this is not a coincidence.&lt;/p&gt;
</content>
 </entry>
 
 
</feed>
